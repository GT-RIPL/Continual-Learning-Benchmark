split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.6009 (0.6009)	0.2202 (0.2202)	0.692 (0.692)	28.00 (54.69)
[100/469]	0.0141 (0.0247)	0.0018 (0.0041)	0.033 (0.133)	100.00 (96.17)
[200/469]	0.0125 (0.0221)	0.0004 (0.0030)	0.031 (0.092)	100.00 (97.26)
[300/469]	0.0098 (0.0213)	0.0014 (0.0027)	0.035 (0.074)	100.00 (97.79)
[400/469]	0.0146 (0.0209)	0.0003 (0.0025)	0.014 (0.064)	100.00 (98.08)
[468/469]	0.0087 (0.0204)	0.0002 (0.0024)	0.021 (0.060)	100.00 (98.19)
 * Train Acc 98.190
 * Val Acc 99.110, Total time 1.27
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1730 (0.1730)	0.1617 (0.1617)	0.030 (0.030)	100.00 (99.22)
[100/469]	0.0166 (0.0193)	0.0017 (0.0036)	0.029 (0.027)	96.55 (99.02)
[200/469]	0.0102 (0.0200)	0.0003 (0.0027)	0.025 (0.025)	92.31 (99.09)
[300/469]	0.0138 (0.0195)	0.0032 (0.0025)	0.017 (0.024)	100.00 (99.14)
[400/469]	0.0155 (0.0193)	0.0029 (0.0024)	0.018 (0.024)	100.00 (99.16)
[468/469]	0.0130 (0.0197)	0.0014 (0.0024)	0.018 (0.024)	100.00 (99.17)
 * Train Acc 99.165
 * Val Acc 99.470, Total time 1.19
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1572 (0.1572)	0.1451 (0.1451)	0.009 (0.009)	100.00 (100.00)
[100/469]	0.0109 (0.0222)	0.0010 (0.0032)	0.018 (0.018)	95.45 (99.40)
[200/469]	0.0150 (0.0205)	0.0019 (0.0026)	0.007 (0.017)	100.00 (99.42)
[300/469]	0.0174 (0.0198)	0.0013 (0.0024)	0.009 (0.017)	100.00 (99.42)
[400/469]	0.0158 (0.0192)	0.0066 (0.0023)	0.013 (0.016)	100.00 (99.44)
[468/469]	0.0101 (0.0188)	0.0002 (0.0023)	0.022 (0.016)	94.12 (99.46)
 * Train Acc 99.457
 * Val Acc 99.600, Total time 1.16
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1510 (0.1510)	0.1386 (0.1386)	0.008 (0.008)	100.00 (100.00)
[100/469]	0.0175 (0.0180)	0.0023 (0.0032)	0.013 (0.011)	100.00 (99.68)
[200/469]	0.0086 (0.0186)	0.0002 (0.0025)	0.016 (0.012)	100.00 (99.60)
[300/469]	0.0115 (0.0175)	0.0005 (0.0025)	0.004 (0.011)	100.00 (99.64)
[400/469]	0.0151 (0.0180)	0.0004 (0.0025)	0.003 (0.011)	100.00 (99.66)
[468/469]	0.0109 (0.0181)	0.0012 (0.0024)	0.006 (0.011)	100.00 (99.65)
 * Train Acc 99.648
 * Val Acc 99.620, Total time 1.28
 * Val Acc 99.620, Total time 1.19
Task All average acc: 99.62
===Summary of experiment repeats: 1 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 9.962 std: 29.886
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2678 (0.2678)	0.1652 (0.1652)	0.689 (0.689)	53.85 (53.91)
[100/469]	0.0215 (0.0210)	0.0016 (0.0036)	0.071 (0.125)	93.75 (96.66)
[200/469]	0.0141 (0.0201)	0.0013 (0.0028)	0.052 (0.087)	100.00 (97.55)
[300/469]	0.0106 (0.0199)	0.0017 (0.0025)	0.074 (0.072)	88.89 (97.90)
[400/469]	0.0245 (0.0202)	0.0065 (0.0023)	0.029 (0.063)	100.00 (98.11)
[468/469]	0.0104 (0.0197)	0.0010 (0.0022)	0.014 (0.059)	100.00 (98.23)
 * Train Acc 98.230
 * Val Acc 99.150, Total time 1.20
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1841 (0.1841)	0.1693 (0.1693)	0.010 (0.010)	100.00 (100.00)
[100/469]	0.0164 (0.0206)	0.0018 (0.0037)	0.012 (0.029)	100.00 (99.04)
[200/469]	0.0134 (0.0196)	0.0017 (0.0027)	0.023 (0.027)	100.00 (99.17)
[300/469]	0.0176 (0.0187)	0.0036 (0.0026)	0.030 (0.027)	100.00 (99.17)
[400/469]	0.0158 (0.0188)	0.0034 (0.0024)	0.011 (0.026)	100.00 (99.19)
[468/469]	0.0486 (0.0189)	0.0001 (0.0024)	0.009 (0.025)	100.00 (99.22)
 * Train Acc 99.222
 * Val Acc 99.460, Total time 1.14
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1494 (0.1494)	0.1343 (0.1343)	0.026 (0.026)	100.00 (99.22)
[100/469]	0.0154 (0.0200)	0.0003 (0.0036)	0.004 (0.019)	100.00 (99.30)
[200/469]	0.0122 (0.0187)	0.0003 (0.0029)	0.032 (0.019)	96.30 (99.37)
[300/469]	0.0091 (0.0185)	0.0002 (0.0026)	0.011 (0.018)	100.00 (99.38)
[400/469]	0.0158 (0.0184)	0.0005 (0.0024)	0.005 (0.017)	100.00 (99.42)
[468/469]	0.0124 (0.0188)	0.0013 (0.0023)	0.002 (0.017)	100.00 (99.42)
 * Train Acc 99.420
 * Val Acc 99.540, Total time 1.16
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2573 (0.2573)	0.1570 (0.1570)	0.016 (0.016)	100.00 (99.22)
[100/469]	0.0133 (0.0218)	0.0016 (0.0041)	0.028 (0.012)	93.75 (99.60)
[200/469]	0.0115 (0.0199)	0.0015 (0.0030)	0.003 (0.012)	100.00 (99.62)
[300/469]	0.0223 (0.0198)	0.0019 (0.0026)	0.002 (0.012)	100.00 (99.64)
[400/469]	0.0196 (0.0197)	0.0034 (0.0026)	0.005 (0.012)	100.00 (99.62)
[468/469]	0.0097 (0.0197)	0.0012 (0.0025)	0.014 (0.012)	100.00 (99.61)
 * Train Acc 99.605
 * Val Acc 99.590, Total time 1.25
 * Val Acc 99.590, Total time 1.24
Task All average acc: 99.59
===Summary of experiment repeats: 2 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59  0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 19.921 std: 39.84200056473069
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1896 (0.1896)	0.1754 (0.1754)	0.710 (0.710)	52.17 (46.09)
[100/469]	0.0190 (0.0203)	0.0040 (0.0037)	0.113 (0.138)	91.18 (96.34)
[200/469]	0.0145 (0.0189)	0.0015 (0.0029)	0.018 (0.093)	100.00 (97.43)
[300/469]	0.0119 (0.0187)	0.0028 (0.0027)	0.021 (0.076)	100.00 (97.86)
[400/469]	0.0164 (0.0185)	0.0012 (0.0024)	0.014 (0.066)	100.00 (98.11)
[468/469]	0.0082 (0.0186)	0.0002 (0.0024)	0.020 (0.061)	100.00 (98.20)
 * Train Acc 98.200
 * Val Acc 99.010, Total time 1.20
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1687 (0.1687)	0.1555 (0.1555)	0.021 (0.021)	100.00 (99.22)
[100/469]	0.0198 (0.0211)	0.0010 (0.0033)	0.007 (0.028)	100.00 (99.08)
[200/469]	0.0215 (0.0210)	0.0029 (0.0028)	0.004 (0.027)	100.00 (99.13)
[300/469]	0.0122 (0.0203)	0.0017 (0.0024)	0.031 (0.026)	95.65 (99.10)
[400/469]	0.0155 (0.0200)	0.0003 (0.0023)	0.011 (0.025)	100.00 (99.15)
[468/469]	0.0124 (0.0196)	0.0011 (0.0022)	0.014 (0.025)	100.00 (99.16)
 * Train Acc 99.162
 * Val Acc 99.270, Total time 1.19
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2104 (0.2104)	0.1954 (0.1954)	0.021 (0.021)	100.00 (99.22)
[100/469]	0.0125 (0.0198)	0.0012 (0.0037)	0.027 (0.018)	95.45 (99.41)
[200/469]	0.0099 (0.0194)	0.0003 (0.0028)	0.029 (0.016)	96.88 (99.49)
[300/469]	0.0109 (0.0194)	0.0011 (0.0025)	0.008 (0.016)	100.00 (99.48)
[400/469]	0.0150 (0.0190)	0.0019 (0.0024)	0.015 (0.017)	100.00 (99.46)
[468/469]	0.0111 (0.0192)	0.0011 (0.0023)	0.004 (0.017)	100.00 (99.47)
 * Train Acc 99.470
 * Val Acc 99.610, Total time 1.22
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1572 (0.1572)	0.1413 (0.1413)	0.010 (0.010)	100.00 (100.00)
[100/469]	0.0167 (0.0197)	0.0018 (0.0032)	0.012 (0.010)	100.00 (99.71)
[200/469]	0.0168 (0.0191)	0.0019 (0.0024)	0.018 (0.011)	100.00 (99.68)
[300/469]	0.0141 (0.0189)	0.0002 (0.0022)	0.032 (0.012)	100.00 (99.64)
[400/469]	0.0189 (0.0187)	0.0036 (0.0021)	0.009 (0.011)	100.00 (99.65)
[468/469]	0.0117 (0.0190)	0.0016 (0.0021)	0.004 (0.011)	100.00 (99.65)
 * Train Acc 99.648
 * Val Acc 99.670, Total time 1.22
 * Val Acc 99.670, Total time 1.16
Task All average acc: 99.67
===Summary of experiment repeats: 3 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67  0.    0.    0.    0.    0.    0.    0.  ]
mean: 29.887999999999998 std: 45.65467770119509
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1515 (0.1515)	0.1395 (0.1395)	0.698 (0.698)	34.62 (45.31)
[100/469]	0.0133 (0.0206)	0.0029 (0.0035)	0.062 (0.145)	92.59 (95.60)
[200/469]	0.0125 (0.0190)	0.0011 (0.0027)	0.053 (0.097)	100.00 (97.05)
[300/469]	0.0166 (0.0180)	0.0020 (0.0026)	0.059 (0.078)	88.89 (97.57)
[400/469]	0.0143 (0.0185)	0.0003 (0.0026)	0.023 (0.068)	100.00 (97.87)
[468/469]	0.0140 (0.0185)	0.0002 (0.0026)	0.020 (0.063)	100.00 (98.02)
 * Train Acc 98.018
 * Val Acc 99.000, Total time 1.19
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1859 (0.1859)	0.1731 (0.1731)	0.022 (0.022)	95.83 (99.22)
[100/469]	0.0196 (0.0204)	0.0022 (0.0035)	0.005 (0.028)	100.00 (99.00)
[200/469]	0.0159 (0.0197)	0.0014 (0.0027)	0.017 (0.027)	100.00 (99.09)
[300/469]	0.0205 (0.0193)	0.0020 (0.0023)	0.013 (0.026)	100.00 (99.13)
[400/469]	0.0118 (0.0197)	0.0011 (0.0022)	0.042 (0.026)	93.10 (99.13)
[468/469]	0.0096 (0.0193)	0.0001 (0.0021)	0.060 (0.025)	95.45 (99.16)
 * Train Acc 99.160
 * Val Acc 99.400, Total time 1.22
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1815 (0.1815)	0.1701 (0.1701)	0.013 (0.013)	100.00 (99.22)
[100/469]	0.0148 (0.0200)	0.0002 (0.0039)	0.004 (0.016)	100.00 (99.40)
[200/469]	0.0105 (0.0186)	0.0002 (0.0029)	0.009 (0.018)	100.00 (99.40)
[300/469]	0.0153 (0.0188)	0.0004 (0.0026)	0.055 (0.018)	96.88 (99.39)
[400/469]	0.0137 (0.0192)	0.0017 (0.0025)	0.052 (0.017)	95.24 (99.43)
[468/469]	0.0165 (0.0193)	0.0015 (0.0024)	0.004 (0.016)	100.00 (99.45)
 * Train Acc 99.450
 * Val Acc 99.480, Total time 1.22
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1642 (0.1642)	0.1402 (0.1402)	0.022 (0.022)	96.15 (99.22)
[100/469]	0.0150 (0.0199)	0.0015 (0.0035)	0.005 (0.012)	100.00 (99.62)
[200/469]	0.0114 (0.0192)	0.0002 (0.0025)	0.010 (0.012)	100.00 (99.62)
[300/469]	0.0189 (0.0194)	0.0027 (0.0023)	0.008 (0.012)	100.00 (99.61)
[400/469]	0.0136 (0.0191)	0.0020 (0.0024)	0.029 (0.012)	96.43 (99.64)
[468/469]	0.0113 (0.0193)	0.0012 (0.0023)	0.013 (0.012)	100.00 (99.61)
 * Train Acc 99.610
 * Val Acc 99.520, Total time 1.19
 * Val Acc 99.520, Total time 1.20
Task All average acc: 99.52
===Summary of experiment repeats: 4 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52  0.    0.    0.    0.    0.    0.  ]
mean: 39.839999999999996 std: 48.79384776793074
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1489 (0.1489)	0.1353 (0.1353)	0.694 (0.694)	51.72 (49.22)
[100/469]	0.0135 (0.0201)	0.0028 (0.0036)	0.062 (0.120)	92.31 (96.68)
[200/469]	0.0123 (0.0200)	0.0011 (0.0028)	0.011 (0.085)	100.00 (97.55)
[300/469]	0.0151 (0.0194)	0.0003 (0.0025)	0.030 (0.070)	96.43 (97.91)
[400/469]	0.0112 (0.0192)	0.0003 (0.0023)	0.056 (0.062)	100.00 (98.10)
[468/469]	0.0122 (0.0195)	0.0011 (0.0023)	0.029 (0.058)	100.00 (98.22)
 * Train Acc 98.223
 * Val Acc 99.100, Total time 1.28
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1920 (0.1920)	0.1786 (0.1786)	0.018 (0.018)	100.00 (99.22)
[100/469]	0.0154 (0.0212)	0.0028 (0.0045)	0.037 (0.028)	95.83 (99.10)
[200/469]	0.0153 (0.0200)	0.0020 (0.0032)	0.025 (0.025)	96.55 (99.17)
[300/469]	0.0724 (0.0200)	0.0013 (0.0027)	0.061 (0.025)	100.00 (99.15)
[400/469]	0.0165 (0.0198)	0.0016 (0.0025)	0.007 (0.025)	100.00 (99.17)
[468/469]	0.0099 (0.0195)	0.0012 (0.0024)	0.068 (0.025)	96.67 (99.18)
 * Train Acc 99.180
 * Val Acc 99.310, Total time 1.26
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2067 (0.2067)	0.1880 (0.1880)	0.013 (0.013)	100.00 (100.00)
[100/469]	0.0127 (0.0213)	0.0013 (0.0039)	0.018 (0.017)	100.00 (99.48)
[200/469]	0.0158 (0.0196)	0.0003 (0.0029)	0.008 (0.016)	100.00 (99.49)
[300/469]	0.0141 (0.0196)	0.0012 (0.0026)	0.034 (0.017)	96.67 (99.46)
[400/469]	0.0116 (0.0193)	0.0013 (0.0024)	0.005 (0.017)	100.00 (99.45)
[468/469]	0.0149 (0.0191)	0.0002 (0.0023)	0.029 (0.017)	100.00 (99.47)
 * Train Acc 99.465
 * Val Acc 99.580, Total time 1.17
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1683 (0.1683)	0.1558 (0.1558)	0.041 (0.041)	95.65 (97.66)
[100/469]	0.0142 (0.0199)	0.0021 (0.0033)	0.007 (0.014)	100.00 (99.58)
[200/469]	0.0114 (0.0195)	0.0017 (0.0027)	0.017 (0.012)	100.00 (99.63)
[300/469]	0.0181 (0.0195)	0.0015 (0.0026)	0.003 (0.011)	100.00 (99.62)
[400/469]	0.0350 (0.0197)	0.0003 (0.0025)	0.017 (0.012)	96.88 (99.57)
[468/469]	0.0136 (0.0194)	0.0002 (0.0024)	0.003 (0.012)	100.00 (99.57)
 * Train Acc 99.572
 * Val Acc 99.630, Total time 1.36
 * Val Acc 99.630, Total time 1.15
Task All average acc: 99.63
===Summary of experiment repeats: 5 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52 99.63  0.    0.    0.    0.    0.  ]
mean: 49.803 std: 49.803012569522345
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2222 (0.2222)	0.2026 (0.2026)	0.694 (0.694)	57.14 (54.69)
[100/469]	0.0488 (0.0212)	0.0003 (0.0042)	0.065 (0.129)	100.00 (96.16)
[200/469]	0.0593 (0.0197)	0.0026 (0.0030)	0.038 (0.089)	96.77 (97.29)
[300/469]	0.0128 (0.0196)	0.0014 (0.0026)	0.048 (0.072)	100.00 (97.81)
[400/469]	0.0098 (0.0196)	0.0002 (0.0024)	0.077 (0.064)	100.00 (98.04)
[468/469]	0.0110 (0.0195)	0.0013 (0.0023)	0.045 (0.059)	100.00 (98.18)
 * Train Acc 98.182
 * Val Acc 98.960, Total time 1.18
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2662 (0.2662)	0.1692 (0.1692)	0.008 (0.008)	100.00 (100.00)
[100/469]	0.0160 (0.0203)	0.0016 (0.0034)	0.005 (0.029)	100.00 (99.02)
[200/469]	0.0123 (0.0182)	0.0017 (0.0025)	0.011 (0.028)	100.00 (99.09)
[300/469]	0.0234 (0.0173)	0.0080 (0.0023)	0.012 (0.027)	100.00 (99.10)
[400/469]	0.0113 (0.0180)	0.0019 (0.0023)	0.051 (0.026)	100.00 (99.15)
[468/469]	0.0087 (0.0179)	0.0002 (0.0023)	0.007 (0.025)	100.00 (99.18)
 * Train Acc 99.182
 * Val Acc 99.440, Total time 1.13
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2271 (0.2271)	0.1401 (0.1401)	0.017 (0.017)	100.00 (100.00)
[100/469]	0.0731 (0.0205)	0.0013 (0.0034)	0.015 (0.018)	100.00 (99.42)
[200/469]	0.0142 (0.0195)	0.0003 (0.0028)	0.011 (0.018)	100.00 (99.44)
[300/469]	0.0123 (0.0199)	0.0013 (0.0027)	0.025 (0.017)	100.00 (99.49)
[400/469]	0.0176 (0.0194)	0.0041 (0.0025)	0.005 (0.017)	100.00 (99.46)
[468/469]	0.0135 (0.0191)	0.0002 (0.0024)	0.020 (0.017)	96.00 (99.44)
 * Train Acc 99.445
 * Val Acc 99.560, Total time 1.20
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1798 (0.1798)	0.1653 (0.1653)	0.024 (0.024)	96.97 (99.22)
[100/469]	0.0157 (0.0206)	0.0029 (0.0041)	0.018 (0.013)	100.00 (99.57)
[200/469]	0.0149 (0.0202)	0.0017 (0.0032)	0.001 (0.012)	100.00 (99.60)
[300/469]	0.0296 (0.0201)	0.0004 (0.0032)	0.003 (0.012)	100.00 (99.60)
[400/469]	0.0123 (0.0201)	0.0019 (0.0031)	0.002 (0.012)	100.00 (99.61)
[468/469]	0.0103 (0.0201)	0.0002 (0.0029)	0.007 (0.011)	100.00 (99.63)
 * Train Acc 99.630
 * Val Acc 99.600, Total time 1.30
 * Val Acc 99.600, Total time 1.28
Task All average acc: 99.6
===Summary of experiment repeats: 6 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52 99.63 99.6   0.    0.    0.    0.  ]
mean: 59.763 std: 48.796298025567474
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1916 (0.1916)	0.1786 (0.1786)	0.696 (0.696)	47.83 (48.44)
[100/469]	0.0155 (0.0204)	0.0022 (0.0038)	0.038 (0.130)	100.00 (96.29)
[200/469]	0.0196 (0.0195)	0.0082 (0.0030)	0.064 (0.090)	94.12 (97.33)
[300/469]	0.0959 (0.0199)	0.0012 (0.0027)	0.049 (0.074)	91.67 (97.78)
[400/469]	0.0211 (0.0203)	0.0019 (0.0025)	0.049 (0.064)	95.83 (98.08)
[468/469]	0.0109 (0.0199)	0.0010 (0.0024)	0.078 (0.059)	95.00 (98.19)
 * Train Acc 98.188
 * Val Acc 99.040, Total time 1.27
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2074 (0.2074)	0.1964 (0.1964)	0.006 (0.006)	100.00 (100.00)
[100/469]	0.0122 (0.0213)	0.0012 (0.0040)	0.010 (0.025)	95.65 (99.17)
[200/469]	0.0191 (0.0201)	0.0038 (0.0030)	0.015 (0.026)	100.00 (99.16)
[300/469]	0.0734 (0.0204)	0.0013 (0.0027)	0.008 (0.026)	100.00 (99.17)
[400/469]	0.0168 (0.0203)	0.0018 (0.0025)	0.002 (0.024)	100.00 (99.22)
[468/469]	0.0365 (0.0204)	0.0014 (0.0024)	0.036 (0.024)	100.00 (99.23)
 * Train Acc 99.230
 * Val Acc 99.300, Total time 1.32
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1829 (0.1829)	0.1636 (0.1636)	0.012 (0.012)	100.00 (99.22)
[100/469]	0.0164 (0.0219)	0.0025 (0.0035)	0.023 (0.017)	95.83 (99.44)
[200/469]	0.0136 (0.0205)	0.0016 (0.0028)	0.011 (0.017)	100.00 (99.41)
[300/469]	0.0128 (0.0198)	0.0004 (0.0025)	0.016 (0.017)	100.00 (99.44)
[400/469]	0.0130 (0.0197)	0.0015 (0.0024)	0.005 (0.017)	100.00 (99.44)
[468/469]	0.0753 (0.0197)	0.0002 (0.0025)	0.026 (0.016)	95.00 (99.44)
 * Train Acc 99.445
 * Val Acc 99.560, Total time 1.20
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1729 (0.1729)	0.1620 (0.1620)	0.027 (0.027)	96.30 (98.44)
[100/469]	0.0165 (0.0234)	0.0030 (0.0038)	0.019 (0.011)	100.00 (99.68)
[200/469]	0.0172 (0.0215)	0.0020 (0.0030)	0.021 (0.012)	96.00 (99.61)
[300/469]	0.0151 (0.0204)	0.0003 (0.0026)	0.027 (0.012)	91.30 (99.60)
[400/469]	0.0156 (0.0208)	0.0016 (0.0024)	0.012 (0.012)	97.30 (99.62)
[468/469]	0.0123 (0.0201)	0.0002 (0.0024)	0.008 (0.012)	100.00 (99.62)
 * Train Acc 99.623
 * Val Acc 99.600, Total time 1.15
 * Val Acc 99.600, Total time 1.25
Task All average acc: 99.6
===Summary of experiment repeats: 7 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52 99.63 99.6  99.6   0.    0.    0.  ]
mean: 69.723 std: 45.644431653817314
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1583 (0.1583)	0.1419 (0.1419)	0.689 (0.689)	46.15 (47.66)
[100/469]	0.1008 (0.0228)	0.0012 (0.0034)	0.041 (0.132)	100.00 (96.34)
[200/469]	0.0175 (0.0195)	0.0017 (0.0029)	0.024 (0.092)	100.00 (97.33)
[300/469]	0.0164 (0.0198)	0.0013 (0.0025)	0.049 (0.076)	100.00 (97.77)
[400/469]	0.0185 (0.0194)	0.0029 (0.0024)	0.054 (0.065)	100.00 (98.04)
[468/469]	0.0098 (0.0191)	0.0011 (0.0023)	0.024 (0.060)	100.00 (98.17)
 * Train Acc 98.165
 * Val Acc 99.100, Total time 1.20
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1640 (0.1640)	0.1520 (0.1520)	0.006 (0.006)	100.00 (100.00)
[100/469]	0.0358 (0.0190)	0.0011 (0.0037)	0.030 (0.026)	96.43 (99.12)
[200/469]	0.0110 (0.0183)	0.0012 (0.0029)	0.006 (0.026)	100.00 (99.15)
[300/469]	0.0177 (0.0180)	0.0019 (0.0025)	0.017 (0.026)	100.00 (99.17)
[400/469]	0.0131 (0.0179)	0.0011 (0.0024)	0.030 (0.024)	100.00 (99.21)
[468/469]	0.0088 (0.0176)	0.0002 (0.0023)	0.025 (0.025)	100.00 (99.20)
 * Train Acc 99.205
 * Val Acc 99.460, Total time 1.22
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1989 (0.1989)	0.1834 (0.1834)	0.016 (0.016)	100.00 (99.22)
[100/469]	0.0216 (0.0214)	0.0073 (0.0043)	0.012 (0.018)	100.00 (99.44)
[200/469]	0.0125 (0.0203)	0.0018 (0.0031)	0.009 (0.017)	100.00 (99.42)
[300/469]	0.0184 (0.0186)	0.0017 (0.0026)	0.009 (0.017)	95.83 (99.41)
[400/469]	0.0143 (0.0184)	0.0018 (0.0025)	0.005 (0.016)	100.00 (99.47)
[468/469]	0.0115 (0.0187)	0.0013 (0.0023)	0.045 (0.016)	100.00 (99.48)
 * Train Acc 99.478
 * Val Acc 99.540, Total time 1.14
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1526 (0.1526)	0.1403 (0.1403)	0.005 (0.005)	100.00 (100.00)
[100/469]	0.0107 (0.0179)	0.0016 (0.0032)	0.006 (0.010)	100.00 (99.71)
[200/469]	0.0122 (0.0160)	0.0003 (0.0028)	0.030 (0.011)	96.15 (99.67)
[300/469]	0.0144 (0.0170)	0.0032 (0.0026)	0.021 (0.011)	96.30 (99.66)
[400/469]	0.0156 (0.0168)	0.0022 (0.0025)	0.019 (0.012)	100.00 (99.62)
[468/469]	0.0092 (0.0169)	0.0012 (0.0025)	0.008 (0.012)	100.00 (99.63)
 * Train Acc 99.633
 * Val Acc 99.660, Total time 1.11
 * Val Acc 99.660, Total time 1.04
Task All average acc: 99.66
===Summary of experiment repeats: 8 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52 99.63 99.6  99.6  99.66  0.    0.  ]
mean: 79.689 std: 39.844519183948
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2371 (0.2371)	0.1590 (0.1590)	0.681 (0.681)	50.00 (51.56)
[100/469]	0.0111 (0.0166)	0.0003 (0.0036)	0.089 (0.142)	100.00 (95.93)
[200/469]	0.0114 (0.0164)	0.0016 (0.0029)	0.037 (0.096)	100.00 (97.11)
[300/469]	0.0109 (0.0165)	0.0017 (0.0025)	0.048 (0.079)	96.15 (97.57)
[400/469]	0.0172 (0.0166)	0.0027 (0.0025)	0.049 (0.068)	91.30 (97.88)
[468/469]	0.0089 (0.0166)	0.0001 (0.0025)	0.053 (0.063)	100.00 (98.05)
 * Train Acc 98.052
 * Val Acc 99.050, Total time 1.16
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1477 (0.1477)	0.1361 (0.1361)	0.024 (0.024)	95.00 (99.22)
[100/469]	0.0086 (0.0180)	0.0003 (0.0038)	0.015 (0.030)	100.00 (98.99)
[200/469]	0.0098 (0.0163)	0.0013 (0.0030)	0.040 (0.028)	100.00 (99.04)
[300/469]	0.0110 (0.0160)	0.0016 (0.0028)	0.015 (0.026)	100.00 (99.12)
[400/469]	0.0108 (0.0162)	0.0018 (0.0028)	0.024 (0.025)	100.00 (99.14)
[468/469]	0.0111 (0.0159)	0.0009 (0.0027)	0.027 (0.025)	95.45 (99.16)
 * Train Acc 99.158
 * Val Acc 99.380, Total time 1.13
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1527 (0.1527)	0.1422 (0.1422)	0.007 (0.007)	100.00 (100.00)
[100/469]	0.0152 (0.0176)	0.0015 (0.0036)	0.014 (0.014)	96.43 (99.50)
[200/469]	0.0671 (0.0167)	0.0013 (0.0028)	0.014 (0.016)	100.00 (99.44)
[300/469]	0.0112 (0.0159)	0.0003 (0.0026)	0.046 (0.016)	100.00 (99.45)
[400/469]	0.0154 (0.0159)	0.0032 (0.0025)	0.005 (0.016)	100.00 (99.46)
[468/469]	0.0097 (0.0158)	0.0011 (0.0024)	0.009 (0.016)	100.00 (99.47)
 * Train Acc 99.465
 * Val Acc 99.540, Total time 1.17
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1665 (0.1665)	0.1549 (0.1549)	0.019 (0.019)	96.30 (99.22)
[100/469]	0.0115 (0.0180)	0.0013 (0.0044)	0.059 (0.012)	96.67 (99.64)
[200/469]	0.0097 (0.0172)	0.0002 (0.0034)	0.016 (0.012)	100.00 (99.65)
[300/469]	0.0104 (0.0164)	0.0011 (0.0030)	0.011 (0.012)	100.00 (99.64)
[400/469]	0.0185 (0.0164)	0.0097 (0.0029)	0.004 (0.011)	100.00 (99.65)
[468/469]	0.0098 (0.0162)	0.0012 (0.0029)	0.008 (0.011)	100.00 (99.67)
 * Train Acc 99.672
 * Val Acc 99.600, Total time 1.15
 * Val Acc 99.600, Total time 1.13
Task All average acc: 99.6
===Summary of experiment repeats: 9 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52 99.63 99.6  99.6  99.66 99.6   0.  ]
mean: 89.649 std: 29.883025767147473
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (1): Linear(in_features=400, out_features=2, bias=True)
    (2): Linear(in_features=400, out_features=2, bias=True)
    (3): Linear(in_features=400, out_features=2, bias=True)
    (4): Linear(in_features=400, out_features=2, bias=True)
    (5): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 574410
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2347 (0.2347)	0.1402 (0.1402)	0.692 (0.692)	44.83 (51.56)
[100/469]	0.0103 (0.0179)	0.0015 (0.0036)	0.054 (0.128)	100.00 (96.36)
[200/469]	0.0118 (0.0175)	0.0018 (0.0029)	0.066 (0.090)	92.31 (97.33)
[300/469]	0.0121 (0.0178)	0.0019 (0.0032)	0.033 (0.074)	100.00 (97.77)
[400/469]	0.0090 (0.0176)	0.0003 (0.0030)	0.018 (0.064)	100.00 (98.04)
[468/469]	0.0103 (0.0171)	0.0010 (0.0028)	0.014 (0.059)	100.00 (98.18)
 * Train Acc 98.178
 * Val Acc 99.150, Total time 1.13
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1495 (0.1495)	0.1379 (0.1379)	0.029 (0.029)	95.83 (98.44)
[100/469]	0.0137 (0.0170)	0.0019 (0.0032)	0.064 (0.025)	100.00 (99.24)
[200/469]	0.0694 (0.0166)	0.0032 (0.0028)	0.023 (0.026)	100.00 (99.18)
[300/469]	0.0140 (0.0157)	0.0050 (0.0025)	0.036 (0.025)	96.55 (99.20)
[400/469]	0.0148 (0.0158)	0.0021 (0.0024)	0.013 (0.024)	96.30 (99.21)
[468/469]	0.0082 (0.0157)	0.0001 (0.0025)	0.005 (0.024)	100.00 (99.21)
 * Train Acc 99.210
 * Val Acc 99.410, Total time 1.16
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2202 (0.2202)	0.2085 (0.2085)	0.011 (0.011)	100.00 (99.22)
[100/469]	0.0191 (0.0189)	0.0103 (0.0045)	0.005 (0.017)	100.00 (99.38)
[200/469]	0.0099 (0.0172)	0.0011 (0.0034)	0.020 (0.017)	94.74 (99.42)
[300/469]	0.0101 (0.0167)	0.0013 (0.0030)	0.005 (0.016)	100.00 (99.45)
[400/469]	0.0155 (0.0159)	0.0025 (0.0027)	0.048 (0.016)	100.00 (99.45)
[468/469]	0.0107 (0.0163)	0.0013 (0.0027)	0.002 (0.016)	100.00 (99.46)
 * Train Acc 99.463
 * Val Acc 99.550, Total time 1.13
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1526 (0.1526)	0.1421 (0.1421)	0.008 (0.008)	100.00 (99.22)
[100/469]	0.0140 (0.0184)	0.0055 (0.0034)	0.008 (0.011)	100.00 (99.63)
[200/469]	0.0116 (0.0173)	0.0030 (0.0028)	0.012 (0.011)	96.30 (99.65)
[300/469]	0.0131 (0.0169)	0.0004 (0.0025)	0.019 (0.012)	95.65 (99.62)
[400/469]	0.0112 (0.0169)	0.0003 (0.0026)	0.009 (0.012)	100.00 (99.60)
[468/469]	0.0077 (0.0169)	0.0001 (0.0025)	0.013 (0.012)	96.55 (99.62)
 * Train Acc 99.623
 * Val Acc 99.630, Total time 1.22
 * Val Acc 99.630, Total time 1.23
Task All average acc: 99.63
===Summary of experiment repeats: 10 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [99.62 99.59 99.67 99.52 99.63 99.6  99.6  99.66 99.6  99.63]
mean: 99.612 std: 0.03969886648255918
reg_coef: 0.0 mean: 99.612 std: 0.03969886648255918
