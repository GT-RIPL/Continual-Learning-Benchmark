split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.329, Loss 0.025
 * Val Acc 99.905, time 0.47
Epoch:1
LR: 0.0001
 * Train Acc 99.818, Loss 0.015
 * Val Acc 99.953, time 0.52
Epoch:2
LR: 0.0001
 * Train Acc 99.858, Loss 0.010
 * Val Acc 99.953, time 0.53
Epoch:3
LR: 0.0001
 * Train Acc 99.897, Loss 0.008
 * Val Acc 99.953, time 0.47
Epoch:4
LR: 0.0001
 * Train Acc 99.921, Loss 0.007
 * Val Acc 99.953, time 0.43
Epoch:5
LR: 0.0001
 * Train Acc 99.929, Loss 0.006
 * Val Acc 99.953, time 0.54
Epoch:6
LR: 0.0001
 * Train Acc 99.945, Loss 0.005
 * Val Acc 99.953, time 0.47
Epoch:7
LR: 0.0001
 * Train Acc 99.953, Loss 0.005
 * Val Acc 99.953, time 0.51
Epoch:8
LR: 0.0001
 * Train Acc 99.921, Loss 0.004
 * Val Acc 99.953, time 0.57
Epoch:9
LR: 0.0001
 * Train Acc 99.945, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 99.961, Loss 0.004
 * Val Acc 99.953, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 99.945, Loss 0.004
 * Val Acc 99.953, time 0.50
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.000001907348633 - mean: 0.00976562686264515 - std: 0.0007707162876613438
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0018109887605533004
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.49
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 83.167, Loss 0.514
 * Val Acc 94.711, time 0.51
Epoch:1
LR: 0.0001
 * Train Acc 95.632, Loss 0.150
 * Val Acc 97.405, time 0.46
Epoch:2
LR: 0.0001
 * Train Acc 97.212, Loss 0.101
 * Val Acc 98.041, time 0.52
Epoch:3
LR: 0.0001
 * Train Acc 97.800, Loss 0.084
 * Val Acc 98.139, time 0.50
Epoch:4
LR: 0.0001
 * Train Acc 98.089, Loss 0.073
 * Val Acc 98.531, time 0.54
Epoch:5
LR: 0.0001
 * Train Acc 98.370, Loss 0.065
 * Val Acc 98.776, time 0.51
Epoch:6
LR: 0.0001
 * Train Acc 98.511, Loss 0.059
 * Val Acc 98.629, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 98.577, Loss 0.055
 * Val Acc 98.874, time 0.52
Epoch:8
LR: 0.0001
 * Train Acc 98.718, Loss 0.051
 * Val Acc 98.972, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 98.801, Loss 0.048
 * Val Acc 98.776, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 98.916, Loss 0.045
 * Val Acc 98.825, time 0.45
Epoch:11
LR: 0.0001
 * Train Acc 98.974, Loss 0.042
 * Val Acc 98.923, time 0.48
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999713897705 - mean: 0.0032226559706032276 - std: 0.0006056383717805147
sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0010085991816595197
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 83.877, time 0.51
validation split name: 2
 * Val Acc 98.923, time 0.53
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 94.833, Loss 0.141
 * Val Acc 97.545, time 0.51
Epoch:1
LR: 0.0001
 * Train Acc 97.407, Loss 0.076
 * Val Acc 98.079, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 97.763, Loss 0.065
 * Val Acc 98.132, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 97.798, Loss 0.058
 * Val Acc 98.239, time 0.52
Epoch:4
LR: 0.0001
 * Train Acc 97.940, Loss 0.052
 * Val Acc 97.972, time 0.46
Epoch:5
LR: 0.0001
 * Train Acc 98.002, Loss 0.049
 * Val Acc 98.292, time 0.48
Epoch:6
LR: 0.0001
 * Train Acc 98.020, Loss 0.046
 * Val Acc 98.239, time 0.44
Epoch:7
LR: 0.0001
 * Train Acc 98.047, Loss 0.044
 * Val Acc 98.453, time 0.42
Epoch:8
LR: 0.0001
 * Train Acc 98.056, Loss 0.043
 * Val Acc 98.399, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 98.135, Loss 0.041
 * Val Acc 98.399, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 98.118, Loss 0.040
 * Val Acc 98.453, time 0.51
Epoch:11
LR: 0.0001
 * Train Acc 98.153, Loss 0.039
 * Val Acc 98.453, time 0.50
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.100000023841858 - mean: 0.0010742187732830644 - std: 0.00022841063037049025
sum: 1.1000001430511475 - mean: 0.0027500002179294825 - std: 0.00039256204036064446
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 61.986, time 0.50
validation split name: 2
 * Val Acc 90.597, time 0.56
validation split name: 3
 * Val Acc 98.453, time 0.41
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 87.901, Loss 0.310
 * Val Acc 88.822, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 89.600, Loss 0.262
 * Val Acc 89.728, time 0.45
Epoch:2
LR: 0.0001
 * Train Acc 89.855, Loss 0.250
 * Val Acc 89.476, time 0.42
Epoch:3
LR: 0.0001
 * Train Acc 90.175, Loss 0.238
 * Val Acc 89.728, time 0.50
Epoch:4
LR: 0.0001
 * Train Acc 90.388, Loss 0.228
 * Val Acc 90.081, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 90.536, Loss 0.220
 * Val Acc 90.030, time 0.46
Epoch:6
LR: 0.0001
 * Train Acc 90.749, Loss 0.212
 * Val Acc 90.131, time 0.49
Epoch:7
LR: 0.0001
 * Train Acc 90.799, Loss 0.204
 * Val Acc 90.433, time 0.41
Epoch:8
LR: 0.0001
 * Train Acc 91.086, Loss 0.197
 * Val Acc 90.433, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 91.102, Loss 0.190
 * Val Acc 90.383, time 0.49
Epoch:10
LR: 0.0001
 * Train Acc 91.308, Loss 0.183
 * Val Acc 90.735, time 0.48
Epoch:11
LR: 0.0001
 * Train Acc 91.299, Loss 0.176
 * Val Acc 91.339, time 0.49
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.707278513815254e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00017066257714759558
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 78.865, time 0.45
validation split name: 2
 * Val Acc 92.850, time 0.46
validation split name: 3
 * Val Acc 91.142, time 0.45
validation split name: 4
 * Val Acc 91.339, time 0.45
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 49.102, Loss 1.227
 * Val Acc 53.253, time 0.47
Epoch:1
LR: 0.0001
 * Train Acc 51.178, Loss 1.130
 * Val Acc 53.908, time 0.46
Epoch:2
LR: 0.0001
 * Train Acc 52.356, Loss 1.076
 * Val Acc 55.421, time 0.50
Epoch:3
LR: 0.0001
 * Train Acc 53.500, Loss 1.029
 * Val Acc 56.329, time 0.46
Epoch:4
LR: 0.0001
 * Train Acc 54.432, Loss 0.989
 * Val Acc 57.539, time 0.50
Epoch:5
LR: 0.0001
 * Train Acc 55.051, Loss 0.954
 * Val Acc 58.245, time 0.45
Epoch:6
LR: 0.0001
 * Train Acc 55.949, Loss 0.923
 * Val Acc 59.203, time 0.52
Epoch:7
LR: 0.0001
 * Train Acc 56.449, Loss 0.894
 * Val Acc 59.657, time 0.48
Epoch:8
LR: 0.0001
 * Train Acc 57.297, Loss 0.867
 * Val Acc 59.909, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 57.797, Loss 0.841
 * Val Acc 60.615, time 0.40
Epoch:10
LR: 0.0001
 * Train Acc 58.280, Loss 0.817
 * Val Acc 60.918, time 0.51
Epoch:11
LR: 0.0001
 * Train Acc 58.771, Loss 0.795
 * Val Acc 61.523, time 0.48
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998986721039 - mean: 0.00011718749010469764 - std: 4.044131492264569e-05
sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 6.936513091204688e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 67.470, time 0.48
validation split name: 2
 * Val Acc 96.327, time 0.56
validation split name: 3
 * Val Acc 93.383, time 0.46
validation split name: 4
 * Val Acc 87.815, time 0.50
validation split name: 5
 * Val Acc 61.523, time 0.47
Task 1 average acc: 99.95271867612293
Task 2 average acc: 91.39984671774532
Task 3 average acc: 83.67859236136307
Task 4 average acc: 88.5491782851023
Task 5 average acc: 81.30367301273421
===Summary of experiment repeats: 1 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301  0.          0.          0.          0.          0.
  0.          0.          0.          0.        ]
mean: 8.13036730127342 std: 24.391101903820264
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.345, Loss 0.023
 * Val Acc 99.953, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 99.850, Loss 0.015
 * Val Acc 99.953, time 0.52
Epoch:2
LR: 0.0001
 * Train Acc 99.874, Loss 0.010
 * Val Acc 99.953, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 99.905, Loss 0.008
 * Val Acc 99.953, time 0.50
Epoch:4
LR: 0.0001
 * Train Acc 99.929, Loss 0.007
 * Val Acc 99.953, time 0.52
Epoch:5
LR: 0.0001
 * Train Acc 99.913, Loss 0.006
 * Val Acc 99.953, time 0.52
Epoch:6
LR: 0.0001
 * Train Acc 99.929, Loss 0.006
 * Val Acc 99.953, time 0.49
Epoch:7
LR: 0.0001
 * Train Acc 99.953, Loss 0.005
 * Val Acc 99.953, time 0.48
Epoch:8
LR: 0.0001
 * Train Acc 99.929, Loss 0.005
 * Val Acc 99.953, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.55
Epoch:10
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:11
LR: 0.0001
 * Train Acc 99.961, Loss 0.003
 * Val Acc 99.905, time 0.49
after batch eps: 10.000000000000217, kappa: 0.5
sum: 9.999999046325684 - mean: 0.009765624068677425 - std: 0.0007658059475943446
sum: 10.0 - mean: 0.02499999850988388 - std: 0.001733961165882647
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.905, time 0.50
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 85.160, Loss 0.483
 * Val Acc 95.201, time 0.50
Epoch:1
LR: 0.0001
 * Train Acc 95.781, Loss 0.135
 * Val Acc 96.915, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 97.014, Loss 0.098
 * Val Acc 97.307, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 97.783, Loss 0.084
 * Val Acc 98.041, time 0.44
Epoch:4
LR: 0.0001
 * Train Acc 98.023, Loss 0.074
 * Val Acc 98.188, time 0.54
Epoch:5
LR: 0.0001
 * Train Acc 98.279, Loss 0.067
 * Val Acc 98.433, time 0.49
Epoch:6
LR: 0.0001
 * Train Acc 98.379, Loss 0.062
 * Val Acc 98.335, time 0.52
Epoch:7
LR: 0.0001
 * Train Acc 98.494, Loss 0.058
 * Val Acc 98.384, time 0.52
Epoch:8
LR: 0.0001
 * Train Acc 98.561, Loss 0.054
 * Val Acc 98.580, time 0.57
Epoch:9
LR: 0.0001
 * Train Acc 98.676, Loss 0.049
 * Val Acc 98.335, time 0.53
Epoch:10
LR: 0.0001
 * Train Acc 98.734, Loss 0.046
 * Val Acc 98.433, time 0.64
Epoch:11
LR: 0.0001
 * Train Acc 98.809, Loss 0.043
 * Val Acc 98.335, time 0.46
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999952316284 - mean: 0.0032226562034338713 - std: 0.000599744264036417
sum: 3.299999952316284 - mean: 0.008249999955296516 - std: 0.0009532052790746093
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 80.993, time 0.55
validation split name: 2
 * Val Acc 98.335, time 0.52
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 93.838, Loss 0.165
 * Val Acc 96.425, time 0.55
Epoch:1
LR: 0.0001
 * Train Acc 96.573, Loss 0.094
 * Val Acc 96.745, time 0.54
Epoch:2
LR: 0.0001
 * Train Acc 96.733, Loss 0.082
 * Val Acc 96.745, time 0.46
Epoch:3
LR: 0.0001
 * Train Acc 96.910, Loss 0.074
 * Val Acc 96.905, time 0.49
Epoch:4
LR: 0.0001
 * Train Acc 97.061, Loss 0.066
 * Val Acc 97.172, time 0.43
Epoch:5
LR: 0.0001
 * Train Acc 97.061, Loss 0.062
 * Val Acc 96.958, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 97.141, Loss 0.059
 * Val Acc 97.012, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 97.159, Loss 0.057
 * Val Acc 97.492, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 97.221, Loss 0.054
 * Val Acc 97.439, time 0.53
Epoch:9
LR: 0.0001
 * Train Acc 97.301, Loss 0.052
 * Val Acc 97.332, time 0.47
Epoch:10
LR: 0.0001
 * Train Acc 97.328, Loss 0.050
 * Val Acc 97.172, time 0.51
Epoch:11
LR: 0.0001
 * Train Acc 97.319, Loss 0.049
 * Val Acc 97.279, time 0.49
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.1000001430511475 - mean: 0.0010742188896983862 - std: 0.00022993289167061448
sum: 1.1000001430511475 - mean: 0.0027500002179294825 - std: 0.0003800129343289882
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 61.466, time 0.50
validation split name: 2
 * Val Acc 90.793, time 0.49
validation split name: 3
 * Val Acc 97.279, time 0.53
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 89.748, Loss 0.259
 * Val Acc 91.440, time 0.51
Epoch:1
LR: 0.0001
 * Train Acc 91.546, Loss 0.209
 * Val Acc 91.793, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 91.825, Loss 0.199
 * Val Acc 92.044, time 0.47
Epoch:3
LR: 0.0001
 * Train Acc 92.079, Loss 0.190
 * Val Acc 92.195, time 0.53
Epoch:4
LR: 0.0001
 * Train Acc 92.301, Loss 0.181
 * Val Acc 92.195, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 92.383, Loss 0.174
 * Val Acc 92.598, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 92.490, Loss 0.168
 * Val Acc 92.749, time 0.51
Epoch:7
LR: 0.0001
 * Train Acc 92.637, Loss 0.162
 * Val Acc 92.800, time 0.52
Epoch:8
LR: 0.0001
 * Train Acc 92.678, Loss 0.156
 * Val Acc 92.749, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 92.884, Loss 0.151
 * Val Acc 92.951, time 0.55
Epoch:10
LR: 0.0001
 * Train Acc 92.998, Loss 0.145
 * Val Acc 92.800, time 0.46
Epoch:11
LR: 0.0001
 * Train Acc 93.007, Loss 0.140
 * Val Acc 93.152, time 0.50
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.35999998450279236 - mean: 0.00035156248486600816 - std: 9.428519842913374e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00016398505249526352
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 73.617, time 0.48
validation split name: 2
 * Val Acc 93.340, time 0.48
validation split name: 3
 * Val Acc 89.488, time 0.49
validation split name: 4
 * Val Acc 93.152, time 0.50
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 54.220, Loss 1.071
 * Val Acc 57.842, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 56.686, Loss 0.984
 * Val Acc 58.951, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 57.949, Loss 0.935
 * Val Acc 60.212, time 0.51
Epoch:3
LR: 0.0001
 * Train Acc 59.203, Loss 0.894
 * Val Acc 60.968, time 0.54
Epoch:4
LR: 0.0001
 * Train Acc 60.051, Loss 0.859
 * Val Acc 61.725, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 60.839, Loss 0.831
 * Val Acc 61.977, time 0.51
Epoch:6
LR: 0.0001
 * Train Acc 61.568, Loss 0.803
 * Val Acc 62.985, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 62.085, Loss 0.778
 * Val Acc 63.893, time 0.43
Epoch:8
LR: 0.0001
 * Train Acc 62.992, Loss 0.755
 * Val Acc 64.599, time 0.48
Epoch:9
LR: 0.0001
 * Train Acc 63.619, Loss 0.732
 * Val Acc 64.851, time 0.53
Epoch:10
LR: 0.0001
 * Train Acc 64.093, Loss 0.711
 * Val Acc 65.255, time 0.53
Epoch:11
LR: 0.0001
 * Train Acc 64.720, Loss 0.692
 * Val Acc 65.406, time 0.48
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998241662979 - mean: 0.00011718748282874003 - std: 3.9673253922956064e-05
sum: 0.12000000476837158 - mean: 0.0003000000142492354 - std: 6.860255234641954e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 56.454, time 0.47
validation split name: 2
 * Val Acc 95.690, time 0.43
validation split name: 3
 * Val Acc 90.715, time 0.48
validation split name: 4
 * Val Acc 90.030, time 0.43
validation split name: 5
 * Val Acc 65.406, time 0.50
Task 1 average acc: 99.90543735224587
Task 2 average acc: 89.66393676065044
Task 3 average acc: 83.17920315410008
Task 4 average acc: 87.39916884872596
Task 5 average acc: 79.65912206108189
===Summary of experiment repeats: 2 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206  0.          0.          0.          0.
  0.          0.          0.          0.        ]
mean: 16.09627950738161 std: 32.19465923582111
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.424, Loss 0.022
 * Val Acc 99.953, time 0.54
Epoch:1
LR: 0.0001
 * Train Acc 99.850, Loss 0.015
 * Val Acc 99.858, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 99.858, Loss 0.010
 * Val Acc 99.905, time 0.53
Epoch:3
LR: 0.0001
 * Train Acc 99.889, Loss 0.008
 * Val Acc 99.953, time 0.48
Epoch:4
LR: 0.0001
 * Train Acc 99.905, Loss 0.007
 * Val Acc 99.953, time 0.51
Epoch:5
LR: 0.0001
 * Train Acc 99.929, Loss 0.006
 * Val Acc 99.953, time 0.52
Epoch:6
LR: 0.0001
 * Train Acc 99.929, Loss 0.006
 * Val Acc 99.953, time 0.48
Epoch:7
LR: 0.0001
 * Train Acc 99.921, Loss 0.005
 * Val Acc 99.953, time 0.52
Epoch:8
LR: 0.0001
 * Train Acc 99.937, Loss 0.004
 * Val Acc 99.953, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 99.937, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 99.961, Loss 0.004
 * Val Acc 99.953, time 0.53
Epoch:11
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.45
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.0 - mean: 0.009765625 - std: 0.0007634685607627034
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0017929010791704059
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.45
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 76.830, Loss 0.542
 * Val Acc 94.025, time 0.50
Epoch:1
LR: 0.0001
 * Train Acc 95.972, Loss 0.140
 * Val Acc 97.405, time 0.52
Epoch:2
LR: 0.0001
 * Train Acc 97.279, Loss 0.097
 * Val Acc 98.139, time 0.52
Epoch:3
LR: 0.0001
 * Train Acc 97.891, Loss 0.081
 * Val Acc 98.335, time 0.52
Epoch:4
LR: 0.0001
 * Train Acc 98.346, Loss 0.070
 * Val Acc 98.335, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 98.428, Loss 0.063
 * Val Acc 98.678, time 0.51
Epoch:6
LR: 0.0001
 * Train Acc 98.710, Loss 0.057
 * Val Acc 98.531, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 98.710, Loss 0.053
 * Val Acc 98.727, time 0.47
Epoch:8
LR: 0.0001
 * Train Acc 98.817, Loss 0.049
 * Val Acc 98.678, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 98.900, Loss 0.045
 * Val Acc 98.727, time 0.51
Epoch:10
LR: 0.0001
 * Train Acc 98.933, Loss 0.042
 * Val Acc 98.874, time 0.53
Epoch:11
LR: 0.0001
 * Train Acc 99.032, Loss 0.040
 * Val Acc 98.923, time 0.49
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999952316284 - mean: 0.0032226562034338713 - std: 0.0006042543682269752
sum: 3.299999952316284 - mean: 0.008249999955296516 - std: 0.0009885004255920649
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 84.208, time 0.49
validation split name: 2
 * Val Acc 98.923, time 0.46
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 93.927, Loss 0.173
 * Val Acc 96.265, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 97.008, Loss 0.086
 * Val Acc 97.065, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 97.443, Loss 0.073
 * Val Acc 97.332, time 0.50
Epoch:3
LR: 0.0001
 * Train Acc 97.523, Loss 0.064
 * Val Acc 97.492, time 0.49
Epoch:4
LR: 0.0001
 * Train Acc 97.638, Loss 0.057
 * Val Acc 97.599, time 0.49
Epoch:5
LR: 0.0001
 * Train Acc 97.869, Loss 0.053
 * Val Acc 97.972, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 97.807, Loss 0.050
 * Val Acc 97.705, time 0.47
Epoch:7
LR: 0.0001
 * Train Acc 97.851, Loss 0.047
 * Val Acc 97.545, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 97.940, Loss 0.045
 * Val Acc 97.972, time 0.48
Epoch:9
LR: 0.0001
 * Train Acc 97.807, Loss 0.044
 * Val Acc 97.972, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 97.896, Loss 0.042
 * Val Acc 98.132, time 0.54
Epoch:11
LR: 0.0001
 * Train Acc 97.940, Loss 0.041
 * Val Acc 98.026, time 0.46
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.1000001430511475 - mean: 0.0010742188896983862 - std: 0.00022888298553880304
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.00039094031671993434
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 58.771, time 0.45
validation split name: 2
 * Val Acc 93.879, time 0.57
validation split name: 3
 * Val Acc 98.026, time 0.47
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 88.156, Loss 0.298
 * Val Acc 90.232, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 90.232, Loss 0.241
 * Val Acc 90.584, time 0.50
Epoch:2
LR: 0.0001
 * Train Acc 90.634, Loss 0.230
 * Val Acc 90.886, time 0.54
Epoch:3
LR: 0.0001
 * Train Acc 90.782, Loss 0.219
 * Val Acc 91.037, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 90.914, Loss 0.209
 * Val Acc 91.188, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 91.086, Loss 0.201
 * Val Acc 91.440, time 0.48
Epoch:6
LR: 0.0001
 * Train Acc 91.357, Loss 0.193
 * Val Acc 91.490, time 0.51
Epoch:7
LR: 0.0001
 * Train Acc 91.464, Loss 0.185
 * Val Acc 91.541, time 0.50
Epoch:8
LR: 0.0001
 * Train Acc 91.710, Loss 0.179
 * Val Acc 91.641, time 0.43
Epoch:9
LR: 0.0001
 * Train Acc 91.743, Loss 0.172
 * Val Acc 91.793, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 91.940, Loss 0.165
 * Val Acc 92.095, time 0.48
Epoch:11
LR: 0.0001
 * Train Acc 92.030, Loss 0.159
 * Val Acc 92.095, time 0.55
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.3600000739097595 - mean: 0.00035156257217749953 - std: 9.654630412114784e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00017341654165647924
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 73.617, time 0.53
validation split name: 2
 * Val Acc 93.438, time 0.48
validation split name: 3
 * Val Acc 89.808, time 0.50
validation split name: 4
 * Val Acc 92.095, time 0.50
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 59.237, Loss 0.904
 * Val Acc 64.095, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 61.424, Loss 0.826
 * Val Acc 65.809, time 0.53
Epoch:2
LR: 0.0001
 * Train Acc 62.932, Loss 0.782
 * Val Acc 66.768, time 0.53
Epoch:3
LR: 0.0001
 * Train Acc 63.941, Loss 0.748
 * Val Acc 66.919, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 64.924, Loss 0.718
 * Val Acc 68.331, time 0.49
Epoch:5
LR: 0.0001
 * Train Acc 65.661, Loss 0.694
 * Val Acc 69.743, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 66.432, Loss 0.672
 * Val Acc 70.499, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 67.169, Loss 0.652
 * Val Acc 70.802, time 0.48
Epoch:8
LR: 0.0001
 * Train Acc 67.746, Loss 0.633
 * Val Acc 71.457, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 68.246, Loss 0.615
 * Val Acc 71.810, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 69.017, Loss 0.598
 * Val Acc 72.113, time 0.49
Epoch:11
LR: 0.0001
 * Train Acc 69.458, Loss 0.582
 * Val Acc 72.214, time 0.49
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998986721039 - mean: 0.00011718749010469764 - std: 3.975096115027554e-05
sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 7.044948142720386e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 59.858, time 0.46
validation split name: 2
 * Val Acc 95.250, time 0.44
validation split name: 3
 * Val Acc 90.342, time 0.43
validation split name: 4
 * Val Acc 89.023, time 0.52
validation split name: 5
 * Val Acc 72.214, time 0.50
Task 1 average acc: 99.95271867612293
Task 2 average acc: 91.56533135131505
Task 3 average acc: 83.55828322685319
Task 4 average acc: 87.23934688322514
Task 5 average acc: 81.33728124571233
===Summary of experiment repeats: 3 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125  0.          0.          0.
  0.          0.          0.          0.        ]
mean: 24.230007631952844 std: 37.01443447481418
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.155, Loss 0.024
 * Val Acc 99.858, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 99.834, Loss 0.015
 * Val Acc 99.953, time 0.52
Epoch:2
LR: 0.0001
 * Train Acc 99.866, Loss 0.010
 * Val Acc 99.953, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 99.905, Loss 0.008
 * Val Acc 99.953, time 0.54
Epoch:4
LR: 0.0001
 * Train Acc 99.905, Loss 0.007
 * Val Acc 99.953, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 99.913, Loss 0.006
 * Val Acc 99.953, time 0.57
Epoch:6
LR: 0.0001
 * Train Acc 99.945, Loss 0.005
 * Val Acc 99.953, time 0.53
Epoch:7
LR: 0.0001
 * Train Acc 99.937, Loss 0.005
 * Val Acc 99.953, time 0.51
Epoch:8
LR: 0.0001
 * Train Acc 99.945, Loss 0.004
 * Val Acc 99.953, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.53
Epoch:11
LR: 0.0001
 * Train Acc 99.953, Loss 0.003
 * Val Acc 99.953, time 0.51
after batch eps: 10.000000000000217, kappa: 0.5
sum: 9.999998092651367 - mean: 0.00976562313735485 - std: 0.0007730296929366887
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0017829806311056018
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.52
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 77.293, Loss 0.530
 * Val Acc 94.123, time 0.47
Epoch:1
LR: 0.0001
 * Train Acc 95.723, Loss 0.140
 * Val Acc 97.307, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 97.130, Loss 0.098
 * Val Acc 97.453, time 0.53
Epoch:3
LR: 0.0001
 * Train Acc 97.684, Loss 0.085
 * Val Acc 98.090, time 0.50
Epoch:4
LR: 0.0001
 * Train Acc 98.114, Loss 0.072
 * Val Acc 98.286, time 0.52
Epoch:5
LR: 0.0001
 * Train Acc 98.296, Loss 0.064
 * Val Acc 98.580, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 98.445, Loss 0.057
 * Val Acc 98.629, time 0.43
Epoch:7
LR: 0.0001
 * Train Acc 98.635, Loss 0.053
 * Val Acc 98.776, time 0.53
Epoch:8
LR: 0.0001
 * Train Acc 98.718, Loss 0.049
 * Val Acc 98.776, time 0.48
Epoch:9
LR: 0.0001
 * Train Acc 98.751, Loss 0.046
 * Val Acc 98.874, time 0.44
Epoch:10
LR: 0.0001
 * Train Acc 98.842, Loss 0.043
 * Val Acc 98.825, time 0.50
Epoch:11
LR: 0.0001
 * Train Acc 98.892, Loss 0.041
 * Val Acc 98.923, time 0.42
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.3000001907348633 - mean: 0.003222656436264515 - std: 0.0006107749068178236
sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0010022999485954642
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 83.499, time 0.55
validation split name: 2
 * Val Acc 98.923, time 0.44
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 93.483, Loss 0.179
 * Val Acc 96.478, time 0.43
Epoch:1
LR: 0.0001
 * Train Acc 96.475, Loss 0.095
 * Val Acc 97.332, time 0.44
Epoch:2
LR: 0.0001
 * Train Acc 96.875, Loss 0.083
 * Val Acc 97.279, time 0.49
Epoch:3
LR: 0.0001
 * Train Acc 96.990, Loss 0.073
 * Val Acc 97.439, time 0.43
Epoch:4
LR: 0.0001
 * Train Acc 97.159, Loss 0.065
 * Val Acc 97.545, time 0.49
Epoch:5
LR: 0.0001
 * Train Acc 97.123, Loss 0.062
 * Val Acc 97.492, time 0.51
Epoch:6
LR: 0.0001
 * Train Acc 97.319, Loss 0.058
 * Val Acc 97.385, time 0.45
Epoch:7
LR: 0.0001
 * Train Acc 97.319, Loss 0.056
 * Val Acc 97.812, time 0.44
Epoch:8
LR: 0.0001
 * Train Acc 97.328, Loss 0.054
 * Val Acc 97.652, time 0.52
Epoch:9
LR: 0.0001
 * Train Acc 97.381, Loss 0.052
 * Val Acc 97.759, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 97.372, Loss 0.050
 * Val Acc 97.705, time 0.44
Epoch:11
LR: 0.0001
 * Train Acc 97.390, Loss 0.049
 * Val Acc 97.866, time 0.45
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.0999999046325684 - mean: 0.0010742186568677425 - std: 0.0002359723875997588
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.00040539854671806097
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 63.121, time 0.50
validation split name: 2
 * Val Acc 90.842, time 0.54
validation split name: 3
 * Val Acc 97.866, time 0.40
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 86.908, Loss 0.336
 * Val Acc 89.778, time 0.44
Epoch:1
LR: 0.0001
 * Train Acc 88.788, Loss 0.284
 * Val Acc 89.930, time 0.49
Epoch:2
LR: 0.0001
 * Train Acc 89.100, Loss 0.272
 * Val Acc 90.181, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 89.305, Loss 0.260
 * Val Acc 90.332, time 0.47
Epoch:4
LR: 0.0001
 * Train Acc 89.510, Loss 0.248
 * Val Acc 90.584, time 0.42
Epoch:5
LR: 0.0001
 * Train Acc 89.633, Loss 0.240
 * Val Acc 90.634, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 89.945, Loss 0.230
 * Val Acc 90.937, time 0.44
Epoch:7
LR: 0.0001
 * Train Acc 90.093, Loss 0.222
 * Val Acc 90.886, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 90.282, Loss 0.214
 * Val Acc 91.088, time 0.46
Epoch:9
LR: 0.0001
 * Train Acc 90.249, Loss 0.206
 * Val Acc 91.339, time 0.53
Epoch:10
LR: 0.0001
 * Train Acc 90.577, Loss 0.199
 * Val Acc 91.188, time 0.52
Epoch:11
LR: 0.0001
 * Train Acc 90.585, Loss 0.192
 * Val Acc 91.490, time 0.49
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.983839117921889e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00017839425709098577
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 79.480, time 0.51
validation split name: 2
 * Val Acc 92.605, time 0.49
validation split name: 3
 * Val Acc 93.436, time 0.46
validation split name: 4
 * Val Acc 91.490, time 0.62
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 47.881, Loss 1.265
 * Val Acc 48.865, time 0.50
Epoch:1
LR: 0.0001
 * Train Acc 49.458, Loss 1.161
 * Val Acc 50.731, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 50.678, Loss 1.098
 * Val Acc 52.244, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 51.703, Loss 1.043
 * Val Acc 53.303, time 0.46
Epoch:4
LR: 0.0001
 * Train Acc 52.492, Loss 0.995
 * Val Acc 54.060, time 0.49
Epoch:5
LR: 0.0001
 * Train Acc 53.424, Loss 0.954
 * Val Acc 55.270, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 54.347, Loss 0.914
 * Val Acc 55.976, time 0.43
Epoch:7
LR: 0.0001
 * Train Acc 55.203, Loss 0.879
 * Val Acc 57.035, time 0.46
Epoch:8
LR: 0.0001
 * Train Acc 56.102, Loss 0.847
 * Val Acc 58.043, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 57.017, Loss 0.816
 * Val Acc 58.649, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 57.712, Loss 0.788
 * Val Acc 59.506, time 0.50
Epoch:11
LR: 0.0001
 * Train Acc 58.458, Loss 0.762
 * Val Acc 60.464, time 0.47
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.12000000476837158 - mean: 0.00011718750465661287 - std: 4.1065417462959886e-05
sum: 0.12000000476837158 - mean: 0.0003000000142492354 - std: 7.201407424872741e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 66.525, time 0.48
validation split name: 2
 * Val Acc 95.593, time 0.48
validation split name: 3
 * Val Acc 92.743, time 0.48
validation split name: 4
 * Val Acc 89.426, time 0.54
validation split name: 5
 * Val Acc 60.464, time 0.49
Task 1 average acc: 99.95271867612293
Task 2 average acc: 91.21072142223704
Task 3 average acc: 83.94280237233012
Task 4 average acc: 89.25303171684301
Task 5 average acc: 80.95002011267069
===Summary of experiment repeats: 4 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011  0.          0.
  0.          0.          0.          0.        ]
mean: 32.325009643219914 std: 39.59224616670194
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.384, Loss 0.020
 * Val Acc 99.953, time 0.51
Epoch:1
LR: 0.0001
 * Train Acc 99.842, Loss 0.013
 * Val Acc 99.953, time 0.45
Epoch:2
LR: 0.0001
 * Train Acc 99.882, Loss 0.009
 * Val Acc 99.953, time 0.51
Epoch:3
LR: 0.0001
 * Train Acc 99.905, Loss 0.008
 * Val Acc 99.953, time 0.46
Epoch:4
LR: 0.0001
 * Train Acc 99.921, Loss 0.007
 * Val Acc 99.953, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 99.937, Loss 0.006
 * Val Acc 99.953, time 0.54
Epoch:6
LR: 0.0001
 * Train Acc 99.937, Loss 0.005
 * Val Acc 99.953, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 99.953, Loss 0.005
 * Val Acc 99.953, time 0.55
Epoch:8
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.41
Epoch:9
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.47
Epoch:10
LR: 0.0001
 * Train Acc 99.953, Loss 0.003
 * Val Acc 99.953, time 0.48
Epoch:11
LR: 0.0001
 * Train Acc 99.968, Loss 0.003
 * Val Acc 99.953, time 0.55
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.0 - mean: 0.009765625 - std: 0.0007568338187411427
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0016937959007918835
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.44
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 79.204, Loss 0.545
 * Val Acc 90.500, time 0.50
Epoch:1
LR: 0.0001
 * Train Acc 94.780, Loss 0.167
 * Val Acc 96.964, time 0.50
Epoch:2
LR: 0.0001
 * Train Acc 97.088, Loss 0.108
 * Val Acc 97.356, time 0.51
Epoch:3
LR: 0.0001
 * Train Acc 97.758, Loss 0.088
 * Val Acc 98.384, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 98.106, Loss 0.074
 * Val Acc 98.286, time 0.49
Epoch:5
LR: 0.0001
 * Train Acc 98.271, Loss 0.066
 * Val Acc 98.678, time 0.47
Epoch:6
LR: 0.0001
 * Train Acc 98.519, Loss 0.059
 * Val Acc 98.629, time 0.44
Epoch:7
LR: 0.0001
 * Train Acc 98.643, Loss 0.054
 * Val Acc 98.874, time 0.51
Epoch:8
LR: 0.0001
 * Train Acc 98.685, Loss 0.050
 * Val Acc 98.580, time 0.42
Epoch:9
LR: 0.0001
 * Train Acc 98.718, Loss 0.047
 * Val Acc 98.825, time 0.49
Epoch:10
LR: 0.0001
 * Train Acc 98.867, Loss 0.043
 * Val Acc 98.629, time 0.49
Epoch:11
LR: 0.0001
 * Train Acc 98.825, Loss 0.041
 * Val Acc 99.021, time 0.44
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999713897705 - mean: 0.0032226559706032276 - std: 0.0006060914602130651
sum: 3.299999713897705 - mean: 0.008249999023973942 - std: 0.0009572281851433218
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 84.303, time 0.45
validation split name: 2
 * Val Acc 99.021, time 0.50
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 93.998, Loss 0.166
 * Val Acc 97.279, time 0.53
Epoch:1
LR: 0.0001
 * Train Acc 97.061, Loss 0.088
 * Val Acc 97.919, time 0.41
Epoch:2
LR: 0.0001
 * Train Acc 97.452, Loss 0.076
 * Val Acc 97.866, time 0.43
Epoch:3
LR: 0.0001
 * Train Acc 97.700, Loss 0.066
 * Val Acc 97.919, time 0.50
Epoch:4
LR: 0.0001
 * Train Acc 97.647, Loss 0.060
 * Val Acc 98.026, time 0.52
Epoch:5
LR: 0.0001
 * Train Acc 97.754, Loss 0.055
 * Val Acc 98.132, time 0.54
Epoch:6
LR: 0.0001
 * Train Acc 97.807, Loss 0.053
 * Val Acc 98.079, time 0.57
Epoch:7
LR: 0.0001
 * Train Acc 97.771, Loss 0.050
 * Val Acc 97.866, time 0.50
Epoch:8
LR: 0.0001
 * Train Acc 97.878, Loss 0.048
 * Val Acc 97.919, time 0.46
Epoch:9
LR: 0.0001
 * Train Acc 97.896, Loss 0.046
 * Val Acc 97.919, time 0.45
Epoch:10
LR: 0.0001
 * Train Acc 97.905, Loss 0.045
 * Val Acc 98.026, time 0.49
Epoch:11
LR: 0.0001
 * Train Acc 98.002, Loss 0.044
 * Val Acc 98.346, time 0.48
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.1000001430511475 - mean: 0.0010742188896983862 - std: 0.00023226106713991612
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.00038791599217802286
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 63.641, time 0.45
validation split name: 2
 * Val Acc 90.157, time 0.40
validation split name: 3
 * Val Acc 98.346, time 0.42
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 89.091, Loss 0.269
 * Val Acc 91.893, time 0.46
Epoch:1
LR: 0.0001
 * Train Acc 90.996, Loss 0.219
 * Val Acc 92.095, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 91.324, Loss 0.208
 * Val Acc 92.346, time 0.52
Epoch:3
LR: 0.0001
 * Train Acc 91.570, Loss 0.198
 * Val Acc 92.447, time 0.54
Epoch:4
LR: 0.0001
 * Train Acc 91.808, Loss 0.187
 * Val Acc 92.800, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 92.046, Loss 0.180
 * Val Acc 92.649, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 92.251, Loss 0.172
 * Val Acc 92.900, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 92.498, Loss 0.165
 * Val Acc 92.800, time 0.47
Epoch:8
LR: 0.0001
 * Train Acc 92.555, Loss 0.159
 * Val Acc 92.900, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 92.752, Loss 0.152
 * Val Acc 93.051, time 0.53
Epoch:10
LR: 0.0001
 * Train Acc 92.818, Loss 0.146
 * Val Acc 93.404, time 0.52
Epoch:11
LR: 0.0001
 * Train Acc 93.015, Loss 0.140
 * Val Acc 93.253, time 0.50
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.698448411654681e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00017062868573702872
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 77.352, time 0.47
validation split name: 2
 * Val Acc 93.928, time 0.49
validation split name: 3
 * Val Acc 92.903, time 0.50
validation split name: 4
 * Val Acc 93.253, time 0.50
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 54.339, Loss 1.048
 * Val Acc 59.506, time 0.46
Epoch:1
LR: 0.0001
 * Train Acc 55.966, Loss 0.966
 * Val Acc 60.313, time 0.44
Epoch:2
LR: 0.0001
 * Train Acc 57.500, Loss 0.917
 * Val Acc 62.279, time 0.49
Epoch:3
LR: 0.0001
 * Train Acc 58.432, Loss 0.877
 * Val Acc 63.389, time 0.43
Epoch:4
LR: 0.0001
 * Train Acc 59.475, Loss 0.841
 * Val Acc 63.540, time 0.42
Epoch:5
LR: 0.0001
 * Train Acc 60.220, Loss 0.811
 * Val Acc 64.801, time 0.47
Epoch:6
LR: 0.0001
 * Train Acc 61.186, Loss 0.782
 * Val Acc 65.204, time 0.51
Epoch:7
LR: 0.0001
 * Train Acc 62.144, Loss 0.757
 * Val Acc 65.608, time 0.47
Epoch:8
LR: 0.0001
 * Train Acc 63.068, Loss 0.731
 * Val Acc 66.364, time 0.48
Epoch:9
LR: 0.0001
 * Train Acc 63.907, Loss 0.708
 * Val Acc 66.818, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 64.449, Loss 0.686
 * Val Acc 67.272, time 0.50
Epoch:11
LR: 0.0001
 * Train Acc 65.178, Loss 0.664
 * Val Acc 67.827, time 0.45
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998986721039 - mean: 0.00011718749010469764 - std: 4.0609276766190305e-05
sum: 0.11999998986721039 - mean: 0.0002999999560415745 - std: 7.051676220726222e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 68.605, time 0.48
validation split name: 2
 * Val Acc 95.642, time 0.51
validation split name: 3
 * Val Acc 89.861, time 0.49
validation split name: 4
 * Val Acc 90.937, time 0.46
validation split name: 5
 * Val Acc 67.827, time 0.40
Task 1 average acc: 99.95271867612293
Task 2 average acc: 91.66158427166617
Task 3 average acc: 84.04771848853589
Task 4 average acc: 89.35885470565552
Task 5 average acc: 82.57421391109077
===Summary of experiment repeats: 5 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011 82.57421391  0.
  0.          0.          0.          0.        ]
mean: 40.58243103432899 std: 40.58778851583778
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.384, Loss 0.022
 * Val Acc 99.905, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 99.803, Loss 0.013
 * Val Acc 99.953, time 0.49
Epoch:2
LR: 0.0001
 * Train Acc 99.882, Loss 0.008
 * Val Acc 99.905, time 0.54
Epoch:3
LR: 0.0001
 * Train Acc 99.858, Loss 0.008
 * Val Acc 99.953, time 0.47
Epoch:4
LR: 0.0001
 * Train Acc 99.905, Loss 0.007
 * Val Acc 99.953, time 0.52
Epoch:5
LR: 0.0001
 * Train Acc 99.913, Loss 0.006
 * Val Acc 99.953, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 99.921, Loss 0.005
 * Val Acc 99.953, time 0.44
Epoch:7
LR: 0.0001
 * Train Acc 99.945, Loss 0.004
 * Val Acc 99.953, time 0.44
Epoch:8
LR: 0.0001
 * Train Acc 99.945, Loss 0.004
 * Val Acc 99.953, time 0.52
Epoch:9
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.45
Epoch:10
LR: 0.0001
 * Train Acc 99.961, Loss 0.004
 * Val Acc 99.953, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 99.961, Loss 0.003
 * Val Acc 99.953, time 0.48
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.0 - mean: 0.009765625 - std: 0.0007776395650580525
sum: 10.000000953674316 - mean: 0.02500000223517418 - std: 0.0017645295010879636
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.43
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 78.683, Loss 0.500
 * Val Acc 95.348, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 95.781, Loss 0.129
 * Val Acc 97.600, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 97.146, Loss 0.091
 * Val Acc 97.992, time 0.50
Epoch:3
LR: 0.0001
 * Train Acc 97.700, Loss 0.079
 * Val Acc 98.482, time 0.48
Epoch:4
LR: 0.0001
 * Train Acc 98.122, Loss 0.068
 * Val Acc 98.433, time 0.53
Epoch:5
LR: 0.0001
 * Train Acc 98.321, Loss 0.060
 * Val Acc 98.727, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 98.594, Loss 0.055
 * Val Acc 98.825, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 98.627, Loss 0.050
 * Val Acc 98.825, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 98.776, Loss 0.046
 * Val Acc 98.727, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 98.875, Loss 0.043
 * Val Acc 98.825, time 0.54
Epoch:10
LR: 0.0001
 * Train Acc 98.949, Loss 0.040
 * Val Acc 98.874, time 0.52
Epoch:11
LR: 0.0001
 * Train Acc 99.007, Loss 0.037
 * Val Acc 99.021, time 0.47
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999713897705 - mean: 0.0032226559706032276 - std: 0.0006078073638491333
sum: 3.299999713897705 - mean: 0.008249999023973942 - std: 0.0009741657413542271
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 82.317, time 0.56
validation split name: 2
 * Val Acc 99.021, time 0.49
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 94.344, Loss 0.157
 * Val Acc 97.332, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 97.319, Loss 0.078
 * Val Acc 97.332, time 0.43
Epoch:2
LR: 0.0001
 * Train Acc 97.461, Loss 0.068
 * Val Acc 97.812, time 0.47
Epoch:3
LR: 0.0001
 * Train Acc 97.692, Loss 0.057
 * Val Acc 97.972, time 0.43
Epoch:4
LR: 0.0001
 * Train Acc 97.949, Loss 0.051
 * Val Acc 97.866, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 97.825, Loss 0.047
 * Val Acc 98.132, time 0.45
Epoch:6
LR: 0.0001
 * Train Acc 97.958, Loss 0.045
 * Val Acc 98.346, time 0.48
Epoch:7
LR: 0.0001
 * Train Acc 98.056, Loss 0.042
 * Val Acc 98.346, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 97.985, Loss 0.040
 * Val Acc 98.239, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 98.127, Loss 0.039
 * Val Acc 98.346, time 0.53
Epoch:10
LR: 0.0001
 * Train Acc 98.118, Loss 0.038
 * Val Acc 98.399, time 0.46
Epoch:11
LR: 0.0001
 * Train Acc 98.100, Loss 0.037
 * Val Acc 98.292, time 0.49
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.100000023841858 - mean: 0.0010742187732830644 - std: 0.00023027686984278262
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0003911229723598808
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 65.201, time 0.51
validation split name: 2
 * Val Acc 89.079, time 0.49
validation split name: 3
 * Val Acc 98.292, time 0.47
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 90.815, Loss 0.233
 * Val Acc 93.001, time 0.47
Epoch:1
LR: 0.0001
 * Train Acc 92.645, Loss 0.183
 * Val Acc 93.404, time 0.45
Epoch:2
LR: 0.0001
 * Train Acc 92.793, Loss 0.175
 * Val Acc 93.404, time 0.43
Epoch:3
LR: 0.0001
 * Train Acc 92.884, Loss 0.167
 * Val Acc 93.555, time 0.48
Epoch:4
LR: 0.0001
 * Train Acc 93.056, Loss 0.159
 * Val Acc 93.656, time 0.46
Epoch:5
LR: 0.0001
 * Train Acc 93.269, Loss 0.153
 * Val Acc 93.807, time 0.46
Epoch:6
LR: 0.0001
 * Train Acc 93.335, Loss 0.147
 * Val Acc 93.958, time 0.44
Epoch:7
LR: 0.0001
 * Train Acc 93.450, Loss 0.142
 * Val Acc 94.109, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 93.630, Loss 0.136
 * Val Acc 93.958, time 0.56
Epoch:9
LR: 0.0001
 * Train Acc 93.622, Loss 0.132
 * Val Acc 94.058, time 0.47
Epoch:10
LR: 0.0001
 * Train Acc 93.721, Loss 0.127
 * Val Acc 94.209, time 0.52
Epoch:11
LR: 0.0001
 * Train Acc 93.844, Loss 0.123
 * Val Acc 94.159, time 0.48
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.526748908683658e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00017229202785529196
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 77.541, time 0.46
validation split name: 2
 * Val Acc 92.997, time 0.45
validation split name: 3
 * Val Acc 93.703, time 0.49
validation split name: 4
 * Val Acc 94.159, time 0.49
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 56.042, Loss 1.086
 * Val Acc 60.161, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 58.500, Loss 0.987
 * Val Acc 61.422, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 59.864, Loss 0.932
 * Val Acc 63.086, time 0.47
Epoch:3
LR: 0.0001
 * Train Acc 60.975, Loss 0.887
 * Val Acc 64.347, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 61.915, Loss 0.847
 * Val Acc 65.154, time 0.45
Epoch:5
LR: 0.0001
 * Train Acc 62.839, Loss 0.813
 * Val Acc 65.860, time 0.51
Epoch:6
LR: 0.0001
 * Train Acc 63.534, Loss 0.782
 * Val Acc 66.011, time 0.47
Epoch:7
LR: 0.0001
 * Train Acc 64.220, Loss 0.754
 * Val Acc 67.070, time 0.42
Epoch:8
LR: 0.0001
 * Train Acc 64.754, Loss 0.729
 * Val Acc 67.827, time 0.46
Epoch:9
LR: 0.0001
 * Train Acc 65.415, Loss 0.703
 * Val Acc 67.927, time 0.47
Epoch:10
LR: 0.0001
 * Train Acc 66.144, Loss 0.680
 * Val Acc 68.986, time 0.52
Epoch:11
LR: 0.0001
 * Train Acc 66.525, Loss 0.658
 * Val Acc 68.684, time 0.55
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998986721039 - mean: 0.00011718749010469764 - std: 4.055122553836554e-05
sum: 0.11999998986721039 - mean: 0.0002999999560415745 - std: 7.25808713468723e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 61.466, time 0.59
validation split name: 2
 * Val Acc 95.984, time 0.49
validation split name: 3
 * Val Acc 92.636, time 0.45
validation split name: 4
 * Val Acc 91.088, time 0.44
validation split name: 5
 * Val Acc 68.684, time 0.50
Task 1 average acc: 99.95271867612293
Task 2 average acc: 90.66867647024773
Task 3 average acc: 84.19090074605523
Task 4 average acc: 89.60021377258583
Task 5 average acc: 81.97150967997071
===Summary of experiment repeats: 6 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011 82.57421391 81.97150968
  0.          0.          0.          0.        ]
mean: 48.77958200232606 std: 39.83450143860398
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.353, Loss 0.019
 * Val Acc 99.953, time 0.56
Epoch:1
LR: 0.0001
 * Train Acc 99.842, Loss 0.012
 * Val Acc 99.953, time 0.49
Epoch:2
LR: 0.0001
 * Train Acc 99.913, Loss 0.008
 * Val Acc 99.953, time 0.44
Epoch:3
LR: 0.0001
 * Train Acc 99.921, Loss 0.007
 * Val Acc 99.953, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 99.913, Loss 0.007
 * Val Acc 99.953, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 99.929, Loss 0.005
 * Val Acc 99.953, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 99.961, Loss 0.005
 * Val Acc 99.953, time 0.52
Epoch:7
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:8
LR: 0.0001
 * Train Acc 99.937, Loss 0.004
 * Val Acc 99.953, time 0.50
Epoch:9
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.45
Epoch:11
LR: 0.0001
 * Train Acc 99.961, Loss 0.003
 * Val Acc 99.953, time 0.50
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.0 - mean: 0.009765625 - std: 0.0007756058475933969
sum: 9.999999046325684 - mean: 0.02499999664723873 - std: 0.0018363159615546465
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.47
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 84.507, Loss 0.443
 * Val Acc 95.446, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 95.831, Loss 0.135
 * Val Acc 96.964, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 97.006, Loss 0.101
 * Val Acc 97.747, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 97.717, Loss 0.082
 * Val Acc 98.335, time 0.49
Epoch:4
LR: 0.0001
 * Train Acc 98.238, Loss 0.069
 * Val Acc 98.531, time 0.50
Epoch:5
LR: 0.0001
 * Train Acc 98.387, Loss 0.061
 * Val Acc 98.482, time 0.53
Epoch:6
LR: 0.0001
 * Train Acc 98.569, Loss 0.054
 * Val Acc 98.825, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 98.660, Loss 0.050
 * Val Acc 98.727, time 0.51
Epoch:8
LR: 0.0001
 * Train Acc 98.734, Loss 0.047
 * Val Acc 98.776, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 98.875, Loss 0.043
 * Val Acc 98.874, time 0.47
Epoch:10
LR: 0.0001
 * Train Acc 98.966, Loss 0.040
 * Val Acc 98.874, time 0.46
Epoch:11
LR: 0.0001
 * Train Acc 98.958, Loss 0.038
 * Val Acc 98.825, time 0.43
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.3000001907348633 - mean: 0.003222656436264515 - std: 0.0006115643191151321
sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0010172877227887511
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 77.778, time 0.46
validation split name: 2
 * Val Acc 98.825, time 0.50
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 94.477, Loss 0.151
 * Val Acc 97.652, time 0.51
Epoch:1
LR: 0.0001
 * Train Acc 97.727, Loss 0.069
 * Val Acc 97.812, time 0.50
Epoch:2
LR: 0.0001
 * Train Acc 98.047, Loss 0.056
 * Val Acc 97.919, time 0.49
Epoch:3
LR: 0.0001
 * Train Acc 98.180, Loss 0.049
 * Val Acc 98.239, time 0.40
Epoch:4
LR: 0.0001
 * Train Acc 98.269, Loss 0.042
 * Val Acc 98.346, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 98.411, Loss 0.039
 * Val Acc 98.186, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 98.464, Loss 0.037
 * Val Acc 98.399, time 0.42
Epoch:7
LR: 0.0001
 * Train Acc 98.491, Loss 0.035
 * Val Acc 98.292, time 0.50
Epoch:8
LR: 0.0001
 * Train Acc 98.508, Loss 0.034
 * Val Acc 98.506, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 98.535, Loss 0.033
 * Val Acc 98.399, time 0.42
Epoch:10
LR: 0.0001
 * Train Acc 98.553, Loss 0.032
 * Val Acc 98.506, time 0.39
Epoch:11
LR: 0.0001
 * Train Acc 98.677, Loss 0.031
 * Val Acc 98.346, time 0.51
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.0999999046325684 - mean: 0.0010742186568677425 - std: 0.00022947444813326
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.00040128399268724024
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 53.995, time 0.48
validation split name: 2
 * Val Acc 90.304, time 0.45
validation split name: 3
 * Val Acc 98.346, time 0.43
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 88.262, Loss 0.296
 * Val Acc 90.383, time 0.44
Epoch:1
LR: 0.0001
 * Train Acc 90.602, Loss 0.237
 * Val Acc 90.534, time 0.51
Epoch:2
LR: 0.0001
 * Train Acc 90.782, Loss 0.227
 * Val Acc 90.584, time 0.51
Epoch:3
LR: 0.0001
 * Train Acc 90.987, Loss 0.214
 * Val Acc 91.088, time 0.49
Epoch:4
LR: 0.0001
 * Train Acc 91.184, Loss 0.203
 * Val Acc 91.339, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 91.398, Loss 0.194
 * Val Acc 91.289, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 91.546, Loss 0.186
 * Val Acc 91.692, time 0.49
Epoch:7
LR: 0.0001
 * Train Acc 91.685, Loss 0.178
 * Val Acc 91.742, time 0.48
Epoch:8
LR: 0.0001
 * Train Acc 91.874, Loss 0.171
 * Val Acc 92.095, time 0.44
Epoch:9
LR: 0.0001
 * Train Acc 91.833, Loss 0.164
 * Val Acc 92.145, time 0.41
Epoch:10
LR: 0.0001
 * Train Acc 91.981, Loss 0.157
 * Val Acc 92.044, time 0.44
Epoch:11
LR: 0.0001
 * Train Acc 92.079, Loss 0.151
 * Val Acc 92.497, time 0.47
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.919935109792277e-05
sum: 0.36000004410743713 - mean: 0.0009000001009553671 - std: 0.00018225834355689585
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 71.395, time 0.52
validation split name: 2
 * Val Acc 92.116, time 0.46
validation split name: 3
 * Val Acc 91.462, time 0.39
validation split name: 4
 * Val Acc 92.497, time 0.46
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 54.373, Loss 1.082
 * Val Acc 58.396, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 56.076, Loss 0.998
 * Val Acc 59.607, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 57.280, Loss 0.948
 * Val Acc 61.170, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 58.297, Loss 0.905
 * Val Acc 62.380, time 0.48
Epoch:4
LR: 0.0001
 * Train Acc 59.076, Loss 0.867
 * Val Acc 62.935, time 0.44
Epoch:5
LR: 0.0001
 * Train Acc 59.881, Loss 0.835
 * Val Acc 63.742, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 60.703, Loss 0.807
 * Val Acc 64.397, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 61.271, Loss 0.778
 * Val Acc 65.053, time 0.44
Epoch:8
LR: 0.0001
 * Train Acc 61.992, Loss 0.752
 * Val Acc 65.809, time 0.41
Epoch:9
LR: 0.0001
 * Train Acc 62.780, Loss 0.727
 * Val Acc 66.011, time 0.40
Epoch:10
LR: 0.0001
 * Train Acc 63.458, Loss 0.703
 * Val Acc 66.515, time 0.45
Epoch:11
LR: 0.0001
 * Train Acc 63.949, Loss 0.681
 * Val Acc 67.474, time 0.48
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999999731779099 - mean: 0.00011718749738065526 - std: 4.156643262831494e-05
sum: 0.11999998986721039 - mean: 0.0002999999560415745 - std: 7.489292329410091e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 57.494, time 0.45
validation split name: 2
 * Val Acc 94.711, time 0.44
validation split name: 3
 * Val Acc 92.583, time 0.49
validation split name: 4
 * Val Acc 88.771, time 0.45
validation split name: 5
 * Val Acc 67.474, time 0.35
Task 1 average acc: 99.95271867612293
Task 2 average acc: 88.30122973120035
Task 3 average acc: 80.88156006136929
Task 4 average acc: 86.86749188142244
Task 5 average acc: 80.20655859103388
===Summary of experiment repeats: 7 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011 82.57421391 81.97150968
 80.20655859  0.          0.          0.        ]
mean: 56.800237861429444 std: 37.19243616880356
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.376, Loss 0.022
 * Val Acc 99.905, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 99.826, Loss 0.013
 * Val Acc 99.953, time 0.47
Epoch:2
LR: 0.0001
 * Train Acc 99.858, Loss 0.009
 * Val Acc 99.953, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 99.897, Loss 0.007
 * Val Acc 99.953, time 0.49
Epoch:4
LR: 0.0001
 * Train Acc 99.929, Loss 0.007
 * Val Acc 99.953, time 0.50
Epoch:5
LR: 0.0001
 * Train Acc 99.929, Loss 0.006
 * Val Acc 99.953, time 0.50
Epoch:6
LR: 0.0001
 * Train Acc 99.929, Loss 0.005
 * Val Acc 99.953, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.56
Epoch:8
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.53
Epoch:9
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.53
Epoch:10
LR: 0.0001
 * Train Acc 99.961, Loss 0.003
 * Val Acc 99.953, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 99.953, Loss 0.003
 * Val Acc 99.953, time 0.50
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.000000953674316 - mean: 0.009765625931322575 - std: 0.0007646902231499553
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0017775679007172585
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.43
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 81.405, Loss 0.490
 * Val Acc 94.662, time 0.42
Epoch:1
LR: 0.0001
 * Train Acc 96.063, Loss 0.129
 * Val Acc 97.356, time 0.46
Epoch:2
LR: 0.0001
 * Train Acc 97.336, Loss 0.091
 * Val Acc 97.943, time 0.47
Epoch:3
LR: 0.0001
 * Train Acc 97.849, Loss 0.079
 * Val Acc 98.188, time 0.48
Epoch:4
LR: 0.0001
 * Train Acc 98.180, Loss 0.070
 * Val Acc 98.335, time 0.52
Epoch:5
LR: 0.0001
 * Train Acc 98.437, Loss 0.062
 * Val Acc 98.433, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 98.585, Loss 0.056
 * Val Acc 98.629, time 0.48
Epoch:7
LR: 0.0001
 * Train Acc 98.693, Loss 0.051
 * Val Acc 98.433, time 0.46
Epoch:8
LR: 0.0001
 * Train Acc 98.817, Loss 0.048
 * Val Acc 98.727, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 98.900, Loss 0.044
 * Val Acc 98.629, time 0.41
Epoch:10
LR: 0.0001
 * Train Acc 99.016, Loss 0.041
 * Val Acc 98.776, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 99.049, Loss 0.039
 * Val Acc 98.776, time 0.44
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999713897705 - mean: 0.0032226559706032276 - std: 0.0006083883927203715
sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0009989097015932202
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 87.896, time 0.47
validation split name: 2
 * Val Acc 98.776, time 0.42
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 94.477, Loss 0.154
 * Val Acc 97.652, time 0.41
Epoch:1
LR: 0.0001
 * Train Acc 97.594, Loss 0.072
 * Val Acc 98.399, time 0.43
Epoch:2
LR: 0.0001
 * Train Acc 97.842, Loss 0.061
 * Val Acc 98.559, time 0.50
Epoch:3
LR: 0.0001
 * Train Acc 98.029, Loss 0.052
 * Val Acc 98.453, time 0.40
Epoch:4
LR: 0.0001
 * Train Acc 98.082, Loss 0.047
 * Val Acc 98.239, time 0.47
Epoch:5
LR: 0.0001
 * Train Acc 98.118, Loss 0.044
 * Val Acc 98.613, time 0.42
Epoch:6
LR: 0.0001
 * Train Acc 98.144, Loss 0.041
 * Val Acc 98.666, time 0.47
Epoch:7
LR: 0.0001
 * Train Acc 98.224, Loss 0.039
 * Val Acc 98.559, time 0.42
Epoch:8
LR: 0.0001
 * Train Acc 98.286, Loss 0.038
 * Val Acc 98.559, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 98.242, Loss 0.038
 * Val Acc 98.666, time 0.40
Epoch:10
LR: 0.0001
 * Train Acc 98.286, Loss 0.036
 * Val Acc 98.559, time 0.42
Epoch:11
LR: 0.0001
 * Train Acc 98.260, Loss 0.035
 * Val Acc 98.773, time 0.43
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.1000001430511475 - mean: 0.0010742188896983862 - std: 0.00022933451691642404
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0003925709752365947
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 60.709, time 0.44
validation split name: 2
 * Val Acc 84.182, time 0.49
validation split name: 3
 * Val Acc 98.773, time 0.50
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 89.748, Loss 0.263
 * Val Acc 91.339, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 91.398, Loss 0.218
 * Val Acc 92.195, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 91.611, Loss 0.206
 * Val Acc 92.095, time 0.49
Epoch:3
LR: 0.0001
 * Train Acc 91.899, Loss 0.196
 * Val Acc 92.044, time 0.46
Epoch:4
LR: 0.0001
 * Train Acc 92.120, Loss 0.186
 * Val Acc 92.447, time 0.43
Epoch:5
LR: 0.0001
 * Train Acc 92.096, Loss 0.179
 * Val Acc 92.497, time 0.43
Epoch:6
LR: 0.0001
 * Train Acc 92.293, Loss 0.172
 * Val Acc 92.548, time 0.42
Epoch:7
LR: 0.0001
 * Train Acc 92.440, Loss 0.165
 * Val Acc 92.850, time 0.46
Epoch:8
LR: 0.0001
 * Train Acc 92.637, Loss 0.158
 * Val Acc 92.850, time 0.49
Epoch:9
LR: 0.0001
 * Train Acc 92.703, Loss 0.152
 * Val Acc 93.001, time 0.45
Epoch:10
LR: 0.0001
 * Train Acc 92.875, Loss 0.146
 * Val Acc 93.202, time 0.43
Epoch:11
LR: 0.0001
 * Train Acc 93.023, Loss 0.140
 * Val Acc 92.850, time 0.46
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.737857908476144e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.00017908751033246517
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 78.534, time 0.51
validation split name: 2
 * Val Acc 91.332, time 0.49
validation split name: 3
 * Val Acc 92.476, time 0.48
validation split name: 4
 * Val Acc 92.850, time 0.44
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 51.000, Loss 1.126
 * Val Acc 54.513, time 0.49
Epoch:1
LR: 0.0001
 * Train Acc 53.254, Loss 1.037
 * Val Acc 55.572, time 0.42
Epoch:2
LR: 0.0001
 * Train Acc 54.593, Loss 0.986
 * Val Acc 57.085, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 55.500, Loss 0.944
 * Val Acc 57.489, time 0.49
Epoch:4
LR: 0.0001
 * Train Acc 56.619, Loss 0.908
 * Val Acc 58.951, time 0.41
Epoch:5
LR: 0.0001
 * Train Acc 57.568, Loss 0.877
 * Val Acc 59.506, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 58.517, Loss 0.849
 * Val Acc 60.313, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 59.229, Loss 0.821
 * Val Acc 60.767, time 0.41
Epoch:8
LR: 0.0001
 * Train Acc 60.008, Loss 0.796
 * Val Acc 61.573, time 0.50
Epoch:9
LR: 0.0001
 * Train Acc 60.432, Loss 0.771
 * Val Acc 61.977, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 61.076, Loss 0.748
 * Val Acc 62.078, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 61.746, Loss 0.726
 * Val Acc 62.885, time 0.43
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998241662979 - mean: 0.00011718748282874003 - std: 4.119096774957143e-05
sum: 0.12000000476837158 - mean: 0.0003000000142492354 - std: 7.420316978823394e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 63.452, time 0.42
validation split name: 2
 * Val Acc 94.809, time 0.50
validation split name: 3
 * Val Acc 91.996, time 0.47
validation split name: 4
 * Val Acc 89.829, time 0.48
validation split name: 5
 * Val Acc 62.885, time 0.45
Task 1 average acc: 99.95271867612293
Task 2 average acc: 93.33584558780966
Task 3 average acc: 81.22135765301529
Task 4 average acc: 88.79806080615182
Task 5 average acc: 80.5939196982149
===Summary of experiment repeats: 8 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011 82.57421391 81.97150968
 80.20655859 80.5939197   0.          0.        ]
mean: 64.85962983125094 std: 32.43933933776742
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.274, Loss 0.019
 * Val Acc 99.905, time 0.47
Epoch:1
LR: 0.0001
 * Train Acc 99.842, Loss 0.011
 * Val Acc 99.953, time 0.49
Epoch:2
LR: 0.0001
 * Train Acc 99.897, Loss 0.009
 * Val Acc 99.953, time 0.47
Epoch:3
LR: 0.0001
 * Train Acc 99.921, Loss 0.007
 * Val Acc 99.953, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 99.921, Loss 0.006
 * Val Acc 99.953, time 0.45
Epoch:5
LR: 0.0001
 * Train Acc 99.921, Loss 0.006
 * Val Acc 99.953, time 0.46
Epoch:6
LR: 0.0001
 * Train Acc 99.945, Loss 0.005
 * Val Acc 99.953, time 0.51
Epoch:7
LR: 0.0001
 * Train Acc 99.945, Loss 0.004
 * Val Acc 99.953, time 0.52
Epoch:8
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 99.961, Loss 0.004
 * Val Acc 99.953, time 0.52
Epoch:10
LR: 0.0001
 * Train Acc 99.953, Loss 0.003
 * Val Acc 99.953, time 0.54
Epoch:11
LR: 0.0001
 * Train Acc 99.968, Loss 0.003
 * Val Acc 99.905, time 0.48
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.0 - mean: 0.009765625 - std: 0.0007772701210342348
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0018031814834102988
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.905, time 0.44
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 80.519, Loss 0.521
 * Val Acc 95.935, time 0.52
Epoch:1
LR: 0.0001
 * Train Acc 96.385, Loss 0.122
 * Val Acc 97.160, time 0.43
Epoch:2
LR: 0.0001
 * Train Acc 97.593, Loss 0.089
 * Val Acc 98.090, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 97.998, Loss 0.079
 * Val Acc 98.384, time 0.47
Epoch:4
LR: 0.0001
 * Train Acc 98.321, Loss 0.070
 * Val Acc 98.482, time 0.49
Epoch:5
LR: 0.0001
 * Train Acc 98.528, Loss 0.063
 * Val Acc 98.825, time 0.47
Epoch:6
LR: 0.0001
 * Train Acc 98.536, Loss 0.057
 * Val Acc 98.433, time 0.45
Epoch:7
LR: 0.0001
 * Train Acc 98.743, Loss 0.053
 * Val Acc 98.776, time 0.47
Epoch:8
LR: 0.0001
 * Train Acc 98.784, Loss 0.050
 * Val Acc 98.727, time 0.45
Epoch:9
LR: 0.0001
 * Train Acc 98.834, Loss 0.046
 * Val Acc 98.727, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 98.858, Loss 0.044
 * Val Acc 98.776, time 0.45
Epoch:11
LR: 0.0001
 * Train Acc 98.974, Loss 0.041
 * Val Acc 98.727, time 0.51
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999952316284 - mean: 0.0032226562034338713 - std: 0.0006099469610489905
sum: 3.299999713897705 - mean: 0.008249999023973942 - std: 0.0010176626965403557
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 79.953, time 0.46
validation split name: 2
 * Val Acc 98.727, time 0.42
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 93.519, Loss 0.176
 * Val Acc 96.211, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 96.742, Loss 0.092
 * Val Acc 96.852, time 0.48
Epoch:2
LR: 0.0001
 * Train Acc 97.097, Loss 0.081
 * Val Acc 97.118, time 0.41
Epoch:3
LR: 0.0001
 * Train Acc 97.185, Loss 0.071
 * Val Acc 97.279, time 0.48
Epoch:4
LR: 0.0001
 * Train Acc 97.363, Loss 0.065
 * Val Acc 97.385, time 0.41
Epoch:5
LR: 0.0001
 * Train Acc 97.319, Loss 0.061
 * Val Acc 97.492, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 97.523, Loss 0.057
 * Val Acc 97.385, time 0.45
Epoch:7
LR: 0.0001
 * Train Acc 97.594, Loss 0.055
 * Val Acc 97.545, time 0.46
Epoch:8
LR: 0.0001
 * Train Acc 97.505, Loss 0.053
 * Val Acc 97.332, time 0.51
Epoch:9
LR: 0.0001
 * Train Acc 97.603, Loss 0.051
 * Val Acc 97.385, time 0.43
Epoch:10
LR: 0.0001
 * Train Acc 97.576, Loss 0.050
 * Val Acc 97.385, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 97.576, Loss 0.048
 * Val Acc 97.439, time 0.44
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.1000001430511475 - mean: 0.0010742188896983862 - std: 0.00023762555792927742
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.00041316193528473377
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 62.506, time 0.43
validation split name: 2
 * Val Acc 91.675, time 0.51
validation split name: 3
 * Val Acc 97.439, time 0.45
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 88.426, Loss 0.289
 * Val Acc 90.886, time 0.40
Epoch:1
LR: 0.0001
 * Train Acc 90.380, Loss 0.236
 * Val Acc 90.987, time 0.50
Epoch:2
LR: 0.0001
 * Train Acc 90.528, Loss 0.226
 * Val Acc 91.037, time 0.40
Epoch:3
LR: 0.0001
 * Train Acc 90.840, Loss 0.215
 * Val Acc 91.239, time 0.45
Epoch:4
LR: 0.0001
 * Train Acc 90.938, Loss 0.206
 * Val Acc 91.390, time 0.43
Epoch:5
LR: 0.0001
 * Train Acc 90.987, Loss 0.199
 * Val Acc 91.591, time 0.47
Epoch:6
LR: 0.0001
 * Train Acc 91.283, Loss 0.191
 * Val Acc 91.641, time 0.48
Epoch:7
LR: 0.0001
 * Train Acc 91.349, Loss 0.183
 * Val Acc 91.692, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 91.488, Loss 0.177
 * Val Acc 91.742, time 0.51
Epoch:9
LR: 0.0001
 * Train Acc 91.488, Loss 0.170
 * Val Acc 91.994, time 0.41
Epoch:10
LR: 0.0001
 * Train Acc 91.767, Loss 0.163
 * Val Acc 91.843, time 0.42
Epoch:11
LR: 0.0001
 * Train Acc 91.890, Loss 0.158
 * Val Acc 92.145, time 0.49
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.882848826237023e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0001774768315954134
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 76.879, time 0.52
validation split name: 2
 * Val Acc 93.585, time 0.42
validation split name: 3
 * Val Acc 91.996, time 0.40
validation split name: 4
 * Val Acc 92.145, time 0.46
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 54.890, Loss 1.043
 * Val Acc 58.800, time 0.48
Epoch:1
LR: 0.0001
 * Train Acc 56.746, Loss 0.974
 * Val Acc 59.657, time 0.44
Epoch:2
LR: 0.0001
 * Train Acc 57.881, Loss 0.932
 * Val Acc 60.010, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 58.975, Loss 0.896
 * Val Acc 60.968, time 0.44
Epoch:4
LR: 0.0001
 * Train Acc 59.542, Loss 0.865
 * Val Acc 61.473, time 0.48
Epoch:5
LR: 0.0001
 * Train Acc 60.203, Loss 0.839
 * Val Acc 62.380, time 0.39
Epoch:6
LR: 0.0001
 * Train Acc 60.788, Loss 0.815
 * Val Acc 62.834, time 0.41
Epoch:7
LR: 0.0001
 * Train Acc 61.288, Loss 0.791
 * Val Acc 63.036, time 0.44
Epoch:8
LR: 0.0001
 * Train Acc 61.754, Loss 0.768
 * Val Acc 63.944, time 0.50
Epoch:9
LR: 0.0001
 * Train Acc 62.280, Loss 0.748
 * Val Acc 64.902, time 0.41
Epoch:10
LR: 0.0001
 * Train Acc 62.966, Loss 0.728
 * Val Acc 65.003, time 0.43
Epoch:11
LR: 0.0001
 * Train Acc 63.466, Loss 0.708
 * Val Acc 65.406, time 0.45
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.11999998986721039 - mean: 0.00011718749010469764 - std: 4.100939258933067e-05
sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 7.190860924310982e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 64.444, time 0.48
validation split name: 2
 * Val Acc 96.474, time 0.48
validation split name: 3
 * Val Acc 91.729, time 0.40
validation split name: 4
 * Val Acc 90.735, time 0.42
validation split name: 5
 * Val Acc 65.406, time 0.45
Task 1 average acc: 99.90543735224587
Task 2 average acc: 89.33972858389888
Task 3 average acc: 83.87312423433242
Task 4 average acc: 88.65122491207931
Task 5 average acc: 81.75770163843599
===Summary of experiment repeats: 9 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011 82.57421391 81.97150968
 80.20655859 80.5939197  81.75770164  0.        ]
mean: 73.03539999509454 std: 24.358670813371944
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=True)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=True)
  (last): ModuleDict(
    (All): LinearInterval(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 573029
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.139, Loss 0.023
 * Val Acc 99.953, time 0.50
Epoch:1
LR: 0.0001
 * Train Acc 99.834, Loss 0.014
 * Val Acc 99.953, time 0.49
Epoch:2
LR: 0.0001
 * Train Acc 99.882, Loss 0.010
 * Val Acc 99.953, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 99.905, Loss 0.008
 * Val Acc 99.953, time 0.45
Epoch:4
LR: 0.0001
 * Train Acc 99.913, Loss 0.007
 * Val Acc 99.953, time 0.52
Epoch:5
LR: 0.0001
 * Train Acc 99.937, Loss 0.006
 * Val Acc 99.953, time 0.46
Epoch:6
LR: 0.0001
 * Train Acc 99.921, Loss 0.006
 * Val Acc 99.953, time 0.55
Epoch:7
LR: 0.0001
 * Train Acc 99.945, Loss 0.005
 * Val Acc 99.953, time 0.44
Epoch:8
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 99.953, Loss 0.004
 * Val Acc 99.953, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 99.968, Loss 0.004
 * Val Acc 99.953, time 0.48
Epoch:11
LR: 0.0001
 * Train Acc 99.953, Loss 0.003
 * Val Acc 99.953, time 0.49
after batch eps: 10.000000000000217, kappa: 0.5
sum: 10.000000953674316 - mean: 0.009765625931322575 - std: 0.0007713274098932743
sum: 10.0 - mean: 0.02499999850988388 - std: 0.0017530560726299882
last-All sum: 10.0 - mean: 0.02499999850988388 - std: 0.0
validation split name: 1
 * Val Acc 99.953, time 0.52
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 80.453, Loss 0.516
 * Val Acc 93.536, time 0.53
Epoch:1
LR: 0.0001
 * Train Acc 95.508, Loss 0.147
 * Val Acc 96.768, time 0.49
Epoch:2
LR: 0.0001
 * Train Acc 96.766, Loss 0.107
 * Val Acc 97.600, time 0.48
Epoch:3
LR: 0.0001
 * Train Acc 97.328, Loss 0.093
 * Val Acc 97.894, time 0.47
Epoch:4
LR: 0.0001
 * Train Acc 97.841, Loss 0.080
 * Val Acc 98.041, time 0.54
Epoch:5
LR: 0.0001
 * Train Acc 98.147, Loss 0.069
 * Val Acc 98.335, time 0.44
Epoch:6
LR: 0.0001
 * Train Acc 98.321, Loss 0.061
 * Val Acc 98.433, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 98.528, Loss 0.055
 * Val Acc 98.531, time 0.45
Epoch:8
LR: 0.0001
 * Train Acc 98.660, Loss 0.050
 * Val Acc 98.433, time 0.47
Epoch:9
LR: 0.0001
 * Train Acc 98.726, Loss 0.046
 * Val Acc 98.580, time 0.46
Epoch:10
LR: 0.0001
 * Train Acc 98.908, Loss 0.042
 * Val Acc 98.678, time 0.51
Epoch:11
LR: 0.0001
 * Train Acc 98.916, Loss 0.039
 * Val Acc 98.678, time 0.44
after batch eps: 3.3000000000000647, kappa: 0.5
sum: 3.299999952316284 - mean: 0.0032226562034338713 - std: 0.0006045073387213051
sum: 3.299999952316284 - mean: 0.008249999955296516 - std: 0.0009655568283051252
last-All sum: 3.3000001907348633 - mean: 0.008249999955296516 - std: 0.0
validation split name: 1
 * Val Acc 86.998, time 0.47
validation split name: 2
 * Val Acc 98.678, time 0.48
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 93.243, Loss 0.183
 * Val Acc 96.958, time 0.43
Epoch:1
LR: 0.0001
 * Train Acc 96.857, Loss 0.088
 * Val Acc 96.692, time 0.50
Epoch:2
LR: 0.0001
 * Train Acc 97.363, Loss 0.073
 * Val Acc 97.118, time 0.45
Epoch:3
LR: 0.0001
 * Train Acc 97.523, Loss 0.063
 * Val Acc 97.492, time 0.42
Epoch:4
LR: 0.0001
 * Train Acc 97.736, Loss 0.056
 * Val Acc 97.492, time 0.46
Epoch:5
LR: 0.0001
 * Train Acc 97.745, Loss 0.052
 * Val Acc 97.385, time 0.40
Epoch:6
LR: 0.0001
 * Train Acc 97.842, Loss 0.049
 * Val Acc 97.385, time 0.50
Epoch:7
LR: 0.0001
 * Train Acc 97.842, Loss 0.047
 * Val Acc 97.705, time 0.43
Epoch:8
LR: 0.0001
 * Train Acc 97.949, Loss 0.044
 * Val Acc 97.759, time 0.40
Epoch:9
LR: 0.0001
 * Train Acc 97.896, Loss 0.044
 * Val Acc 97.439, time 0.41
Epoch:10
LR: 0.0001
 * Train Acc 97.878, Loss 0.042
 * Val Acc 97.545, time 0.39
Epoch:11
LR: 0.0001
 * Train Acc 97.887, Loss 0.041
 * Val Acc 97.759, time 0.44
after batch eps: 1.100000000000022, kappa: 0.5
sum: 1.0999999046325684 - mean: 0.0010742186568677425 - std: 0.00022966018877923489
sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0003816637326963246
last-All sum: 1.100000023841858 - mean: 0.002749999985098839 - std: 0.0
validation split name: 1
 * Val Acc 60.757, time 0.41
validation split name: 2
 * Val Acc 90.304, time 0.54
validation split name: 3
 * Val Acc 97.759, time 0.50
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 91.669, Loss 0.214
 * Val Acc 93.505, time 0.50
Epoch:1
LR: 0.0001
 * Train Acc 93.713, Loss 0.160
 * Val Acc 93.706, time 0.50
Epoch:2
LR: 0.0001
 * Train Acc 93.885, Loss 0.154
 * Val Acc 93.958, time 0.52
Epoch:3
LR: 0.0001
 * Train Acc 93.983, Loss 0.146
 * Val Acc 94.058, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 94.172, Loss 0.140
 * Val Acc 93.857, time 0.51
Epoch:5
LR: 0.0001
 * Train Acc 94.312, Loss 0.134
 * Val Acc 94.058, time 0.57
Epoch:6
LR: 0.0001
 * Train Acc 94.262, Loss 0.130
 * Val Acc 94.058, time 0.46
Epoch:7
LR: 0.0001
 * Train Acc 94.386, Loss 0.125
 * Val Acc 94.159, time 0.60
Epoch:8
LR: 0.0001
 * Train Acc 94.517, Loss 0.120
 * Val Acc 94.159, time 0.56
Epoch:9
LR: 0.0001
 * Train Acc 94.566, Loss 0.116
 * Val Acc 94.361, time 0.48
Epoch:10
LR: 0.0001
 * Train Acc 94.673, Loss 0.112
 * Val Acc 94.562, time 0.48
Epoch:11
LR: 0.0001
 * Train Acc 94.689, Loss 0.108
 * Val Acc 94.109, time 0.44
after batch eps: 0.3599999999999909, kappa: 0.5
sum: 0.36000001430511475 - mean: 0.0003515625139698386 - std: 9.31139657041058e-05
sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0001655646919971332
last-All sum: 0.36000001430511475 - mean: 0.0009000000427477062 - std: 0.0
validation split name: 1
 * Val Acc 73.002, time 0.55
validation split name: 2
 * Val Acc 92.899, time 0.42
validation split name: 3
 * Val Acc 91.035, time 0.46
validation split name: 4
 * Val Acc 94.109, time 0.50
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.0001
 * Train Acc 55.712, Loss 1.060
 * Val Acc 59.708, time 0.45
Epoch:1
LR: 0.0001
 * Train Acc 58.508, Loss 0.964
 * Val Acc 61.826, time 0.46
Epoch:2
LR: 0.0001
 * Train Acc 59.839, Loss 0.913
 * Val Acc 62.683, time 0.49
Epoch:3
LR: 0.0001
 * Train Acc 61.008, Loss 0.870
 * Val Acc 64.196, time 0.51
Epoch:4
LR: 0.0001
 * Train Acc 62.025, Loss 0.835
 * Val Acc 64.851, time 0.50
Epoch:5
LR: 0.0001
 * Train Acc 63.102, Loss 0.803
 * Val Acc 65.860, time 0.41
Epoch:6
LR: 0.0001
 * Train Acc 63.763, Loss 0.776
 * Val Acc 67.221, time 0.43
Epoch:7
LR: 0.0001
 * Train Acc 64.534, Loss 0.751
 * Val Acc 68.028, time 0.47
Epoch:8
LR: 0.0001
 * Train Acc 65.102, Loss 0.726
 * Val Acc 68.381, time 0.51
Epoch:9
LR: 0.0001
 * Train Acc 65.805, Loss 0.704
 * Val Acc 68.936, time 0.43
Epoch:10
LR: 0.0001
 * Train Acc 66.280, Loss 0.682
 * Val Acc 69.592, time 0.47
Epoch:11
LR: 0.0001
 * Train Acc 66.890, Loss 0.661
 * Val Acc 69.793, time 0.42
after batch eps: 0.11999999999999841, kappa: 0.5
sum: 0.12000000476837158 - mean: 0.00011718750465661287 - std: 4.021028507850133e-05
sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 7.118267967598513e-05
last-All sum: 0.11999999731779099 - mean: 0.00029999998514540493 - std: 0.0
validation split name: 1
 * Val Acc 60.473, time 0.48
validation split name: 2
 * Val Acc 95.593, time 0.43
validation split name: 3
 * Val Acc 91.355, time 0.45
validation split name: 4
 * Val Acc 90.332, time 0.45
validation split name: 5
 * Val Acc 69.793, time 0.48
Task 1 average acc: 99.95271867612293
Task 2 average acc: 92.83770141450347
Task 3 average acc: 82.93964325866999
Task 4 average acc: 87.7613656725284
Task 5 average acc: 81.50926558859165
===Summary of experiment repeats: 10 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [81.30367301 79.65912206 81.33728125 80.95002011 82.57421391 81.97150968
 80.20655859 80.5939197  81.75770164 81.50926559]
mean: 81.1863265539537 std: 0.8190937624121623
reg_coef: 0.0 mean: 81.1863265539537 std: 0.8190937624121623
* kappa decrease from 1 to 0.5 in 4.0 epoch
* eps increase by [10.0, 3.3, 1.1, 0.36, 0.12] every 12.0 epoch
* maximal eps: 10.0
* tasks were trained [12] epoch with clipping
