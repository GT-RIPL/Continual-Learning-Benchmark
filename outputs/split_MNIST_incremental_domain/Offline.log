split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.4668 (0.4668)	0.2007 (0.2007)	0.695 (0.695)	51.56 (51.56)
[100/469]	0.0103 (0.0170)	0.0003 (0.0089)	0.162 (0.296)	94.53 (87.31)
[200/469]	0.0253 (0.0152)	0.0224 (0.0088)	0.194 (0.234)	92.97 (90.44)
[300/469]	0.0098 (0.0145)	0.0002 (0.0085)	0.109 (0.198)	97.66 (92.08)
[400/469]	0.0045 (0.0140)	0.0003 (0.0080)	0.185 (0.174)	93.75 (93.19)
[468/469]	0.0037 (0.0138)	0.0002 (0.0080)	0.121 (0.162)	93.75 (93.67)
 * Train Acc 93.675
 * Val Acc 97.140, Total time 1.25
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1466 (0.1466)	0.1419 (0.1419)	0.108 (0.108)	96.09 (96.09)
[100/469]	0.0493 (0.0146)	0.0446 (0.0100)	0.062 (0.074)	97.66 (97.53)
[200/469]	0.0051 (0.0138)	0.0003 (0.0087)	0.082 (0.074)	96.88 (97.48)
[300/469]	0.0034 (0.0131)	0.0002 (0.0083)	0.044 (0.071)	98.44 (97.54)
[400/469]	0.0232 (0.0130)	0.0193 (0.0080)	0.056 (0.069)	98.44 (97.64)
[468/469]	0.0043 (0.0129)	0.0002 (0.0079)	0.092 (0.067)	95.83 (97.69)
 * Train Acc 97.685
 * Val Acc 98.110, Total time 1.15
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1478 (0.1478)	0.1387 (0.1387)	0.056 (0.056)	97.66 (97.66)
[100/469]	0.0073 (0.0147)	0.0032 (0.0088)	0.048 (0.050)	97.66 (98.20)
[200/469]	0.0351 (0.0137)	0.0308 (0.0083)	0.042 (0.050)	99.22 (98.27)
[300/469]	0.0031 (0.0133)	0.0002 (0.0079)	0.041 (0.049)	96.88 (98.28)
[400/469]	0.0259 (0.0134)	0.0191 (0.0081)	0.061 (0.048)	97.66 (98.33)
[468/469]	0.0099 (0.0133)	0.0002 (0.0080)	0.025 (0.047)	100.00 (98.34)
 * Train Acc 98.345
 * Val Acc 98.320, Total time 1.26
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1702 (0.1702)	0.1659 (0.1659)	0.084 (0.084)	96.88 (96.88)
[100/469]	0.0044 (0.0143)	0.0003 (0.0091)	0.020 (0.036)	100.00 (98.82)
[200/469]	0.0243 (0.0133)	0.0198 (0.0083)	0.033 (0.038)	98.44 (98.71)
[300/469]	0.0243 (0.0131)	0.0144 (0.0079)	0.123 (0.037)	96.09 (98.73)
[400/469]	0.0305 (0.0131)	0.0267 (0.0079)	0.032 (0.036)	99.22 (98.78)
[468/469]	0.0027 (0.0130)	0.0001 (0.0078)	0.023 (0.036)	98.96 (98.78)
 * Train Acc 98.785
 * Val Acc 98.550, Total time 1.25
 * Val Acc 98.550, Total time 1.18
Task All average acc: 98.55
===Summary of experiment repeats: 1 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 9.855 std: 29.564999999999998
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1496 (0.1496)	0.1380 (0.1380)	0.697 (0.697)	46.88 (46.88)
[100/469]	0.0129 (0.0146)	0.0104 (0.0094)	0.266 (0.325)	88.28 (85.81)
[200/469]	0.0102 (0.0137)	0.0002 (0.0086)	0.107 (0.252)	96.09 (89.58)
[300/469]	0.0031 (0.0131)	0.0002 (0.0078)	0.110 (0.210)	96.09 (91.53)
[400/469]	0.0146 (0.0132)	0.0057 (0.0080)	0.157 (0.182)	95.31 (92.78)
[468/469]	0.0099 (0.0132)	0.0001 (0.0080)	0.076 (0.169)	94.79 (93.34)
 * Train Acc 93.343
 * Val Acc 97.140, Total time 1.07
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1644 (0.1644)	0.1603 (0.1603)	0.059 (0.059)	97.66 (97.66)
[100/469]	0.0034 (0.0142)	0.0003 (0.0088)	0.058 (0.077)	97.66 (97.36)
[200/469]	0.0043 (0.0139)	0.0003 (0.0088)	0.043 (0.074)	97.66 (97.37)
[300/469]	0.0149 (0.0139)	0.0047 (0.0086)	0.070 (0.072)	97.66 (97.47)
[400/469]	0.0290 (0.0136)	0.0232 (0.0083)	0.038 (0.070)	99.22 (97.56)
[468/469]	0.0024 (0.0134)	0.0001 (0.0081)	0.046 (0.068)	96.88 (97.59)
 * Train Acc 97.595
 * Val Acc 98.020, Total time 1.09
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1824 (0.1824)	0.1715 (0.1715)	0.070 (0.070)	98.44 (98.44)
[100/469]	0.0237 (0.0150)	0.0205 (0.0097)	0.040 (0.050)	99.22 (98.29)
[200/469]	0.0045 (0.0134)	0.0002 (0.0086)	0.014 (0.050)	100.00 (98.30)
[300/469]	0.0031 (0.0131)	0.0002 (0.0080)	0.076 (0.050)	96.09 (98.31)
[400/469]	0.0044 (0.0130)	0.0002 (0.0080)	0.074 (0.049)	97.66 (98.32)
[468/469]	0.0028 (0.0128)	0.0001 (0.0078)	0.031 (0.049)	98.96 (98.33)
 * Train Acc 98.325
 * Val Acc 98.150, Total time 1.14
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1901 (0.1901)	0.1847 (0.1847)	0.065 (0.065)	96.88 (96.88)
[100/469]	0.0238 (0.0148)	0.0207 (0.0103)	0.024 (0.033)	99.22 (98.82)
[200/469]	0.0027 (0.0135)	0.0002 (0.0083)	0.039 (0.037)	98.44 (98.78)
[300/469]	0.0042 (0.0132)	0.0002 (0.0083)	0.028 (0.036)	98.44 (98.77)
[400/469]	0.0044 (0.0131)	0.0003 (0.0080)	0.066 (0.037)	98.44 (98.76)
[468/469]	0.0146 (0.0130)	0.0051 (0.0079)	0.013 (0.037)	100.00 (98.78)
 * Train Acc 98.777
 * Val Acc 98.670, Total time 1.14
 * Val Acc 98.670, Total time 1.16
Task All average acc: 98.67
===Summary of experiment repeats: 2 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67  0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 19.722 std: 39.44400912686235
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1526 (0.1526)	0.1437 (0.1437)	0.707 (0.707)	42.19 (42.19)
[100/469]	0.0271 (0.0142)	0.0237 (0.0088)	0.165 (0.320)	94.53 (86.19)
[200/469]	0.0099 (0.0131)	0.0016 (0.0079)	0.116 (0.248)	96.88 (89.86)
[300/469]	0.0284 (0.0130)	0.0238 (0.0076)	0.135 (0.206)	94.53 (91.74)
[400/469]	0.0034 (0.0129)	0.0002 (0.0077)	0.067 (0.178)	98.44 (92.99)
[468/469]	0.0031 (0.0127)	0.0001 (0.0075)	0.061 (0.164)	97.92 (93.61)
 * Train Acc 93.608
 * Val Acc 97.170, Total time 1.19
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2203 (0.2203)	0.2143 (0.2143)	0.064 (0.064)	96.88 (96.88)
[100/469]	0.0092 (0.0150)	0.0047 (0.0099)	0.074 (0.074)	96.09 (97.49)
[200/469]	0.0039 (0.0135)	0.0003 (0.0082)	0.101 (0.072)	95.31 (97.56)
[300/469]	0.0029 (0.0133)	0.0002 (0.0082)	0.036 (0.067)	99.22 (97.66)
[400/469]	0.0040 (0.0133)	0.0002 (0.0080)	0.026 (0.065)	100.00 (97.74)
[468/469]	0.0037 (0.0132)	0.0001 (0.0079)	0.085 (0.065)	96.88 (97.76)
 * Train Acc 97.763
 * Val Acc 98.160, Total time 1.21
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1673 (0.1673)	0.1626 (0.1626)	0.081 (0.081)	96.88 (96.88)
[100/469]	0.0031 (0.0145)	0.0002 (0.0090)	0.027 (0.044)	99.22 (98.56)
[200/469]	0.0375 (0.0141)	0.0331 (0.0090)	0.042 (0.045)	97.66 (98.51)
[300/469]	0.0214 (0.0133)	0.0176 (0.0082)	0.015 (0.045)	100.00 (98.45)
[400/469]	0.0047 (0.0133)	0.0003 (0.0084)	0.037 (0.046)	98.44 (98.40)
[468/469]	0.0213 (0.0135)	0.0169 (0.0086)	0.023 (0.046)	98.96 (98.41)
 * Train Acc 98.407
 * Val Acc 98.410, Total time 1.16
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1627 (0.1627)	0.1582 (0.1582)	0.024 (0.024)	98.44 (98.44)
[100/469]	0.0164 (0.0140)	0.0107 (0.0092)	0.016 (0.032)	99.22 (98.93)
[200/469]	0.0046 (0.0136)	0.0003 (0.0083)	0.010 (0.033)	100.00 (98.87)
[300/469]	0.0050 (0.0135)	0.0002 (0.0083)	0.032 (0.035)	99.22 (98.80)
[400/469]	0.0114 (0.0131)	0.0030 (0.0079)	0.024 (0.034)	99.22 (98.85)
[468/469]	0.0140 (0.0130)	0.0046 (0.0078)	0.057 (0.035)	96.88 (98.84)
 * Train Acc 98.837
 * Val Acc 98.630, Total time 1.23
 * Val Acc 98.630, Total time 1.19
Task All average acc: 98.63
===Summary of experiment repeats: 3 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63  0.    0.    0.    0.    0.    0.    0.  ]
mean: 29.585 std: 45.19184223950159
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1589 (0.1589)	0.1509 (0.1509)	0.696 (0.696)	43.75 (43.75)
[100/469]	0.0306 (0.0141)	0.0264 (0.0092)	0.226 (0.293)	93.75 (87.55)
[200/469]	0.0084 (0.0134)	0.0003 (0.0085)	0.114 (0.227)	96.88 (90.85)
[300/469]	0.0175 (0.0132)	0.0130 (0.0083)	0.083 (0.191)	97.66 (92.48)
[400/469]	0.0184 (0.0130)	0.0090 (0.0081)	0.082 (0.166)	97.66 (93.58)
[468/469]	0.0103 (0.0129)	0.0018 (0.0080)	0.118 (0.155)	96.88 (94.07)
 * Train Acc 94.072
 * Val Acc 97.220, Total time 1.15
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1619 (0.1619)	0.1563 (0.1563)	0.022 (0.022)	100.00 (100.00)
[100/469]	0.0088 (0.0147)	0.0042 (0.0091)	0.065 (0.072)	98.44 (97.51)
[200/469]	0.0065 (0.0136)	0.0036 (0.0085)	0.081 (0.069)	96.88 (97.63)
[300/469]	0.0058 (0.0132)	0.0002 (0.0080)	0.028 (0.067)	99.22 (97.65)
[400/469]	0.0029 (0.0131)	0.0002 (0.0081)	0.098 (0.065)	97.66 (97.73)
[468/469]	0.0037 (0.0130)	0.0002 (0.0079)	0.113 (0.065)	96.88 (97.74)
 * Train Acc 97.738
 * Val Acc 97.990, Total time 1.12
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1513 (0.1513)	0.1419 (0.1419)	0.036 (0.036)	99.22 (99.22)
[100/469]	0.0327 (0.0144)	0.0282 (0.0089)	0.031 (0.047)	100.00 (98.45)
[200/469]	0.0099 (0.0137)	0.0003 (0.0085)	0.045 (0.050)	98.44 (98.33)
[300/469]	0.0301 (0.0134)	0.0250 (0.0081)	0.035 (0.050)	97.66 (98.31)
[400/469]	0.0100 (0.0132)	0.0003 (0.0081)	0.083 (0.048)	97.66 (98.34)
[468/469]	0.0099 (0.0131)	0.0001 (0.0079)	0.023 (0.048)	98.96 (98.34)
 * Train Acc 98.343
 * Val Acc 98.380, Total time 1.16
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1462 (0.1462)	0.1416 (0.1416)	0.019 (0.019)	100.00 (100.00)
[100/469]	0.0195 (0.0142)	0.0093 (0.0087)	0.043 (0.033)	98.44 (98.90)
[200/469]	0.0189 (0.0132)	0.0159 (0.0082)	0.062 (0.036)	97.66 (98.80)
[300/469]	0.0100 (0.0130)	0.0018 (0.0079)	0.008 (0.036)	100.00 (98.84)
[400/469]	0.0029 (0.0129)	0.0002 (0.0078)	0.024 (0.036)	99.22 (98.84)
[468/469]	0.0027 (0.0129)	0.0001 (0.0077)	0.034 (0.037)	98.96 (98.78)
 * Train Acc 98.783
 * Val Acc 98.400, Total time 1.18
 * Val Acc 98.400, Total time 1.37
Task All average acc: 98.4
===Summary of experiment repeats: 4 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4   0.    0.    0.    0.    0.    0.  ]
mean: 39.425 std: 48.285610744817134
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2370 (0.2370)	0.2271 (0.2271)	0.702 (0.702)	51.56 (51.56)
[100/469]	0.0037 (0.0178)	0.0003 (0.0124)	0.204 (0.304)	92.19 (86.83)
[200/469]	0.0034 (0.0155)	0.0002 (0.0101)	0.118 (0.240)	95.31 (90.18)
[300/469]	0.0240 (0.0156)	0.0206 (0.0099)	0.106 (0.204)	96.09 (91.91)
[400/469]	0.0049 (0.0153)	0.0003 (0.0098)	0.102 (0.180)	95.31 (92.96)
[468/469]	0.0098 (0.0153)	0.0002 (0.0097)	0.125 (0.168)	94.79 (93.50)
 * Train Acc 93.497
 * Val Acc 97.120, Total time 1.21
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1953 (0.1953)	0.1871 (0.1871)	0.090 (0.090)	97.66 (97.66)
[100/469]	0.0228 (0.0155)	0.0189 (0.0104)	0.059 (0.079)	96.88 (97.19)
[200/469]	0.0148 (0.0148)	0.0083 (0.0100)	0.041 (0.076)	98.44 (97.29)
[300/469]	0.0042 (0.0145)	0.0016 (0.0096)	0.034 (0.074)	99.22 (97.37)
[400/469]	0.0388 (0.0143)	0.0348 (0.0094)	0.056 (0.072)	98.44 (97.44)
[468/469]	0.0048 (0.0140)	0.0001 (0.0090)	0.025 (0.071)	98.96 (97.50)
 * Train Acc 97.502
 * Val Acc 98.140, Total time 1.20
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1806 (0.1806)	0.1711 (0.1711)	0.027 (0.027)	99.22 (99.22)
[100/469]	0.0483 (0.0160)	0.0432 (0.0102)	0.054 (0.055)	98.44 (98.07)
[200/469]	0.0031 (0.0149)	0.0002 (0.0092)	0.044 (0.053)	98.44 (98.14)
[300/469]	0.0047 (0.0143)	0.0003 (0.0090)	0.016 (0.051)	99.22 (98.18)
[400/469]	0.0317 (0.0142)	0.0283 (0.0089)	0.037 (0.051)	98.44 (98.21)
[468/469]	0.0097 (0.0140)	0.0064 (0.0088)	0.008 (0.050)	100.00 (98.25)
 * Train Acc 98.247
 * Val Acc 98.440, Total time 1.29
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1682 (0.1682)	0.1626 (0.1626)	0.027 (0.027)	99.22 (99.22)
[100/469]	0.0201 (0.0160)	0.0125 (0.0103)	0.039 (0.037)	98.44 (98.72)
[200/469]	0.0029 (0.0139)	0.0002 (0.0091)	0.023 (0.036)	99.22 (98.74)
[300/469]	0.0038 (0.0139)	0.0003 (0.0089)	0.036 (0.038)	98.44 (98.63)
[400/469]	0.0162 (0.0138)	0.0082 (0.0090)	0.034 (0.038)	99.22 (98.65)
[468/469]	0.0099 (0.0138)	0.0011 (0.0088)	0.077 (0.038)	96.88 (98.67)
 * Train Acc 98.675
 * Val Acc 98.610, Total time 1.26
 * Val Acc 98.610, Total time 1.21
Task All average acc: 98.61
===Summary of experiment repeats: 5 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4  98.61  0.    0.    0.    0.    0.  ]
mean: 49.286 std: 49.28604512435544
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2665 (0.2665)	0.2601 (0.2601)	0.697 (0.697)	50.00 (50.00)
[100/469]	0.0276 (0.0177)	0.0226 (0.0131)	0.223 (0.321)	91.41 (86.15)
[200/469]	0.0055 (0.0153)	0.0003 (0.0102)	0.165 (0.249)	94.53 (89.80)
[300/469]	0.0030 (0.0143)	0.0002 (0.0092)	0.083 (0.207)	96.88 (91.80)
[400/469]	0.0031 (0.0143)	0.0001 (0.0091)	0.094 (0.181)	96.09 (92.97)
[468/469]	0.0035 (0.0141)	0.0001 (0.0090)	0.076 (0.167)	96.88 (93.52)
 * Train Acc 93.520
 * Val Acc 97.360, Total time 1.24
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1794 (0.1794)	0.1738 (0.1738)	0.083 (0.083)	96.88 (96.88)
[100/469]	0.0096 (0.0156)	0.0003 (0.0109)	0.188 (0.079)	95.31 (97.22)
[200/469]	0.0047 (0.0144)	0.0002 (0.0093)	0.085 (0.078)	96.88 (97.22)
[300/469]	0.0069 (0.0142)	0.0002 (0.0090)	0.027 (0.073)	99.22 (97.36)
[400/469]	0.0061 (0.0138)	0.0003 (0.0088)	0.060 (0.070)	98.44 (97.49)
[468/469]	0.0062 (0.0136)	0.0030 (0.0086)	0.151 (0.068)	93.75 (97.53)
 * Train Acc 97.532
 * Val Acc 97.860, Total time 1.27
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1699 (0.1699)	0.1651 (0.1651)	0.041 (0.041)	98.44 (98.44)
[100/469]	0.0037 (0.0136)	0.0002 (0.0085)	0.046 (0.049)	98.44 (98.31)
[200/469]	0.0321 (0.0136)	0.0289 (0.0091)	0.046 (0.047)	98.44 (98.38)
[300/469]	0.0323 (0.0136)	0.0294 (0.0091)	0.056 (0.047)	97.66 (98.41)
[400/469]	0.0073 (0.0137)	0.0002 (0.0091)	0.103 (0.047)	97.66 (98.38)
[468/469]	0.0274 (0.0137)	0.0238 (0.0091)	0.032 (0.046)	98.96 (98.38)
 * Train Acc 98.383
 * Val Acc 98.390, Total time 1.20
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2100 (0.2100)	0.2011 (0.2011)	0.030 (0.030)	98.44 (98.44)
[100/469]	0.0340 (0.0158)	0.0302 (0.0107)	0.024 (0.034)	99.22 (98.93)
[200/469]	0.0034 (0.0144)	0.0003 (0.0091)	0.089 (0.038)	96.88 (98.74)
[300/469]	0.0026 (0.0146)	0.0002 (0.0093)	0.014 (0.037)	100.00 (98.72)
[400/469]	0.0119 (0.0141)	0.0034 (0.0091)	0.038 (0.036)	98.44 (98.76)
[468/469]	0.0096 (0.0137)	0.0001 (0.0088)	0.007 (0.036)	100.00 (98.76)
 * Train Acc 98.758
 * Val Acc 98.360, Total time 1.31
 * Val Acc 98.360, Total time 1.13
Task All average acc: 98.36
===Summary of experiment repeats: 6 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4  98.61 98.36  0.    0.    0.    0.  ]
mean: 59.122 std: 48.2729957222462
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1847 (0.1847)	0.1767 (0.1767)	0.684 (0.684)	62.50 (62.50)
[100/469]	0.0366 (0.0144)	0.0242 (0.0103)	0.214 (0.294)	90.62 (87.41)
[200/469]	0.0037 (0.0142)	0.0003 (0.0094)	0.260 (0.231)	91.41 (90.56)
[300/469]	0.0036 (0.0141)	0.0002 (0.0092)	0.094 (0.194)	96.09 (92.32)
[400/469]	0.0316 (0.0137)	0.0234 (0.0088)	0.092 (0.171)	96.88 (93.39)
[468/469]	0.0096 (0.0135)	0.0001 (0.0086)	0.136 (0.159)	95.83 (93.90)
 * Train Acc 93.897
 * Val Acc 97.220, Total time 1.30
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2393 (0.2393)	0.2320 (0.2320)	0.112 (0.112)	95.31 (95.31)
[100/469]	0.0041 (0.0156)	0.0015 (0.0112)	0.053 (0.074)	98.44 (97.47)
[200/469]	0.0030 (0.0141)	0.0002 (0.0092)	0.059 (0.073)	97.66 (97.50)
[300/469]	0.0096 (0.0137)	0.0015 (0.0089)	0.073 (0.070)	97.66 (97.58)
[400/469]	0.0028 (0.0133)	0.0002 (0.0086)	0.064 (0.068)	97.66 (97.64)
[468/469]	0.0025 (0.0132)	0.0001 (0.0085)	0.055 (0.066)	98.96 (97.68)
 * Train Acc 97.682
 * Val Acc 98.130, Total time 1.22
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1868 (0.1868)	0.1800 (0.1800)	0.054 (0.054)	97.66 (97.66)
[100/469]	0.0027 (0.0152)	0.0002 (0.0103)	0.057 (0.053)	98.44 (98.22)
[200/469]	0.0079 (0.0136)	0.0052 (0.0086)	0.040 (0.050)	98.44 (98.31)
[300/469]	0.0165 (0.0129)	0.0137 (0.0083)	0.036 (0.050)	98.44 (98.31)
[400/469]	0.0257 (0.0129)	0.0227 (0.0080)	0.059 (0.048)	98.44 (98.38)
[468/469]	0.0028 (0.0129)	0.0001 (0.0080)	0.068 (0.047)	96.88 (98.38)
 * Train Acc 98.380
 * Val Acc 98.470, Total time 1.19
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2153 (0.2153)	0.2094 (0.2094)	0.032 (0.032)	98.44 (98.44)
[100/469]	0.0128 (0.0152)	0.0045 (0.0104)	0.030 (0.035)	99.22 (98.86)
[200/469]	0.0029 (0.0144)	0.0002 (0.0092)	0.051 (0.035)	96.88 (98.85)
[300/469]	0.0356 (0.0140)	0.0323 (0.0087)	0.029 (0.035)	99.22 (98.83)
[400/469]	0.0097 (0.0139)	0.0004 (0.0087)	0.062 (0.036)	98.44 (98.77)
[468/469]	0.0060 (0.0137)	0.0019 (0.0086)	0.038 (0.036)	98.96 (98.76)
 * Train Acc 98.760
 * Val Acc 98.490, Total time 1.23
 * Val Acc 98.490, Total time 1.12
Task All average acc: 98.49
===Summary of experiment repeats: 7 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4  98.61 98.36 98.49  0.    0.    0.  ]
mean: 68.971 std: 45.15221111972259
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1633 (0.1633)	0.1582 (0.1582)	0.693 (0.693)	46.09 (46.09)
[100/469]	0.0031 (0.0157)	0.0002 (0.0107)	0.229 (0.323)	89.06 (86.34)
[200/469]	0.0283 (0.0140)	0.0231 (0.0091)	0.123 (0.246)	95.31 (90.01)
[300/469]	0.0096 (0.0140)	0.0002 (0.0092)	0.093 (0.205)	96.88 (91.92)
[400/469]	0.0036 (0.0136)	0.0003 (0.0086)	0.109 (0.179)	96.88 (93.07)
[468/469]	0.0034 (0.0133)	0.0002 (0.0084)	0.057 (0.165)	96.88 (93.62)
 * Train Acc 93.625
 * Val Acc 97.280, Total time 1.30
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1732 (0.1732)	0.1669 (0.1669)	0.087 (0.087)	96.88 (96.88)
[100/469]	0.0047 (0.0144)	0.0013 (0.0085)	0.068 (0.071)	97.66 (97.58)
[200/469]	0.0099 (0.0137)	0.0002 (0.0084)	0.066 (0.069)	98.44 (97.56)
[300/469]	0.0029 (0.0134)	0.0002 (0.0082)	0.046 (0.069)	98.44 (97.58)
[400/469]	0.0330 (0.0134)	0.0295 (0.0083)	0.103 (0.067)	96.09 (97.64)
[468/469]	0.0033 (0.0133)	0.0001 (0.0083)	0.053 (0.066)	98.96 (97.68)
 * Train Acc 97.683
 * Val Acc 98.380, Total time 1.28
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1733 (0.1733)	0.1689 (0.1689)	0.044 (0.044)	97.66 (97.66)
[100/469]	0.0244 (0.0149)	0.0215 (0.0100)	0.051 (0.046)	98.44 (98.41)
[200/469]	0.0028 (0.0142)	0.0002 (0.0095)	0.045 (0.047)	97.66 (98.43)
[300/469]	0.0097 (0.0136)	0.0003 (0.0086)	0.024 (0.048)	99.22 (98.36)
[400/469]	0.0143 (0.0135)	0.0118 (0.0086)	0.047 (0.046)	97.66 (98.42)
[468/469]	0.0096 (0.0135)	0.0001 (0.0086)	0.065 (0.046)	96.88 (98.42)
 * Train Acc 98.425
 * Val Acc 98.470, Total time 1.22
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1879 (0.1879)	0.1814 (0.1814)	0.067 (0.067)	97.66 (97.66)
[100/469]	0.0270 (0.0147)	0.0240 (0.0095)	0.019 (0.031)	99.22 (98.94)
[200/469]	0.0081 (0.0139)	0.0002 (0.0087)	0.020 (0.031)	100.00 (98.94)
[300/469]	0.0292 (0.0138)	0.0259 (0.0091)	0.018 (0.034)	99.22 (98.80)
[400/469]	0.0029 (0.0138)	0.0002 (0.0089)	0.021 (0.034)	98.44 (98.79)
[468/469]	0.0097 (0.0140)	0.0001 (0.0091)	0.027 (0.035)	97.92 (98.77)
 * Train Acc 98.765
 * Val Acc 98.660, Total time 1.10
 * Val Acc 98.660, Total time 1.29
Task All average acc: 98.66
===Summary of experiment repeats: 8 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4  98.61 98.36 98.49 98.66  0.    0.  ]
mean: 78.837 std: 39.41862505212479
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1637 (0.1637)	0.1592 (0.1592)	0.695 (0.695)	45.31 (45.31)
[100/469]	0.0118 (0.0133)	0.0034 (0.0088)	0.194 (0.294)	93.75 (87.33)
[200/469]	0.0027 (0.0130)	0.0002 (0.0082)	0.101 (0.229)	97.66 (90.68)
[300/469]	0.0301 (0.0132)	0.0272 (0.0083)	0.083 (0.193)	97.66 (92.33)
[400/469]	0.0140 (0.0129)	0.0052 (0.0082)	0.095 (0.169)	96.09 (93.44)
[468/469]	0.0089 (0.0129)	0.0001 (0.0081)	0.105 (0.157)	96.88 (93.95)
 * Train Acc 93.955
 * Val Acc 97.310, Total time 1.23
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2411 (0.2411)	0.2328 (0.2328)	0.092 (0.092)	96.88 (96.88)
[100/469]	0.0051 (0.0154)	0.0018 (0.0115)	0.084 (0.079)	96.88 (97.31)
[200/469]	0.0044 (0.0143)	0.0002 (0.0097)	0.083 (0.072)	95.31 (97.50)
[300/469]	0.0137 (0.0142)	0.0105 (0.0095)	0.059 (0.071)	98.44 (97.56)
[400/469]	0.0063 (0.0136)	0.0013 (0.0088)	0.029 (0.068)	100.00 (97.64)
[468/469]	0.0117 (0.0136)	0.0085 (0.0087)	0.036 (0.066)	100.00 (97.67)
 * Train Acc 97.665
 * Val Acc 98.180, Total time 1.21
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1678 (0.1678)	0.1630 (0.1630)	0.068 (0.068)	97.66 (97.66)
[100/469]	0.0351 (0.0162)	0.0315 (0.0108)	0.078 (0.049)	96.09 (98.31)
[200/469]	0.0028 (0.0144)	0.0002 (0.0095)	0.038 (0.049)	97.66 (98.25)
[300/469]	0.0033 (0.0140)	0.0001 (0.0090)	0.055 (0.049)	99.22 (98.29)
[400/469]	0.0097 (0.0136)	0.0003 (0.0087)	0.031 (0.049)	99.22 (98.32)
[468/469]	0.0122 (0.0134)	0.0023 (0.0085)	0.030 (0.048)	100.00 (98.34)
 * Train Acc 98.345
 * Val Acc 98.290, Total time 1.38
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1997 (0.1997)	0.1940 (0.1940)	0.019 (0.019)	99.22 (99.22)
[100/469]	0.0061 (0.0146)	0.0032 (0.0091)	0.053 (0.037)	98.44 (98.91)
[200/469]	0.0342 (0.0140)	0.0292 (0.0089)	0.031 (0.037)	99.22 (98.75)
[300/469]	0.0027 (0.0135)	0.0002 (0.0085)	0.015 (0.037)	100.00 (98.75)
[400/469]	0.0130 (0.0135)	0.0024 (0.0085)	0.045 (0.037)	98.44 (98.75)
[468/469]	0.0056 (0.0136)	0.0018 (0.0086)	0.040 (0.037)	98.96 (98.75)
 * Train Acc 98.748
 * Val Acc 98.040, Total time 1.38
 * Val Acc 98.040, Total time 1.27
Task All average acc: 98.04
===Summary of experiment repeats: 9 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4  98.61 98.36 98.49 98.66 98.04  0.  ]
mean: 88.64099999999999 std: 29.547552335176597
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=True)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model: 571202
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2339 (0.2339)	0.2291 (0.2291)	0.705 (0.705)	42.19 (42.19)
[100/469]	0.0107 (0.0149)	0.0002 (0.0099)	0.241 (0.312)	92.97 (86.59)
[200/469]	0.0041 (0.0142)	0.0003 (0.0088)	0.150 (0.241)	93.75 (90.19)
[300/469]	0.0100 (0.0137)	0.0018 (0.0083)	0.103 (0.200)	96.09 (92.09)
[400/469]	0.0346 (0.0136)	0.0314 (0.0083)	0.088 (0.176)	96.88 (93.12)
[468/469]	0.0032 (0.0135)	0.0002 (0.0082)	0.118 (0.163)	94.79 (93.66)
 * Train Acc 93.662
 * Val Acc 97.310, Total time 1.22
Epoch:1
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1737 (0.1737)	0.1666 (0.1666)	0.077 (0.077)	96.88 (96.88)
[100/469]	0.0185 (0.0156)	0.0079 (0.0103)	0.080 (0.077)	96.88 (97.28)
[200/469]	0.0046 (0.0147)	0.0003 (0.0093)	0.085 (0.073)	96.88 (97.50)
[300/469]	0.0104 (0.0146)	0.0029 (0.0091)	0.141 (0.071)	95.31 (97.56)
[400/469]	0.0032 (0.0144)	0.0002 (0.0092)	0.060 (0.069)	98.44 (97.64)
[468/469]	0.0035 (0.0142)	0.0001 (0.0089)	0.089 (0.067)	95.83 (97.70)
 * Train Acc 97.697
 * Val Acc 98.060, Total time 1.19
Epoch:2
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1650 (0.1650)	0.1598 (0.1598)	0.073 (0.073)	96.88 (96.88)
[100/469]	0.0061 (0.0154)	0.0003 (0.0099)	0.036 (0.050)	99.22 (98.49)
[200/469]	0.0212 (0.0155)	0.0164 (0.0104)	0.040 (0.050)	99.22 (98.40)
[300/469]	0.0261 (0.0148)	0.0220 (0.0095)	0.013 (0.051)	100.00 (98.31)
[400/469]	0.0108 (0.0146)	0.0002 (0.0092)	0.042 (0.049)	97.66 (98.32)
[468/469]	0.0100 (0.0143)	0.0008 (0.0089)	0.067 (0.049)	97.92 (98.36)
 * Train Acc 98.363
 * Val Acc 98.340, Total time 1.18
Epoch:3
LR: 0.0001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1739 (0.1739)	0.1674 (0.1674)	0.041 (0.041)	98.44 (98.44)
[100/469]	0.0043 (0.0153)	0.0003 (0.0101)	0.063 (0.037)	98.44 (98.73)
[200/469]	0.0097 (0.0145)	0.0003 (0.0094)	0.006 (0.036)	100.00 (98.77)
[300/469]	0.0466 (0.0146)	0.0385 (0.0096)	0.045 (0.037)	99.22 (98.69)
[400/469]	0.0399 (0.0142)	0.0361 (0.0091)	0.026 (0.036)	99.22 (98.74)
[468/469]	0.0030 (0.0141)	0.0001 (0.0091)	0.026 (0.037)	98.96 (98.74)
 * Train Acc 98.738
 * Val Acc 98.460, Total time 1.20
 * Val Acc 98.460, Total time 1.22
Task All average acc: 98.46
===Summary of experiment repeats: 10 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.55 98.67 98.63 98.4  98.61 98.36 98.49 98.66 98.04 98.46]
mean: 98.487 std: 0.18088946901353642
reg_coef: 0.0 mean: 98.487 std: 0.18088946901353642
